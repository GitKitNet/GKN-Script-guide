Глава 12. Внешние команды, программы и утилиты

Благодаря стандартизации набора команд UNIX-систем, сценарии, на языке командной оболочки, могут быть легко перенесены из системы в систему практически без изменений. Мощь сценариев складывется из наборв системных команд и директив командной оболочки с простыми программными конструкциями.

12.1. Базовые команды

Первая команда, с которой сталкиваются новички

ls
Команда вывода "списка" файлов. Многие недооценивают всю мощь этой скромной команды. Например, с ключом -R, рекурсивный обход дерева каталогов, командв ls выводит содержимое каталогов в виде древовидной структуры. Вот еще ряд любопытных ключей (опций) команды ls: -S -- сортировка по размеру файлов, -t -- сортировка по времени последней модификации файла и -i -- выводит список файлов с их inode (см. Пример 12-3).

Пример 12-1. Создание оглавления диска для записи CDR, с помощью команды ls

#!/bin/bash
# burn-cd.sh
# Сценарий, автоматизирующий процесс прожигания CDR.


SPEED=2          # Если ваше "железо" поддерживает более высокую скорость записи -- можете увеличить этот параметр
IMAGEFILE=cdimage.iso
CONTENTSFILE=contents
DEFAULTDIR=/opt  # В этом каталоге находятся файлы, которые будут записаны на CD.
                 # Каталог должен существовать.

# Используется пакет "cdrecord" от Joerg Schilling.
# (http://www.fokus.gmd.de/nthp/employees/schilling/cdrecord.html)

#  Если этот сценарий предполагается запускать с правами обычного пользователя,
#+ то необходимо установить флаг suid на cdrecord
#+ (chmod u+s /usr/bin/cdrecord, эта команда должна быть выполнена root-ом).

if [ -z "$1" ]
then
  IMAGE_DIRECTORY=$DEFAULTDIR
  # Каталог по-умолчанию, если иной каталог не задан из командной строки.
else
    IMAGE_DIRECTORY=$1
fi

# Создать файл "table of contents".
ls -lRF $IMAGE_DIRECTORY > $IMAGE_DIRECTORY/$CONTENTSFILE
# Ключ "l" -- "расширенный" формат вывода списка файлов.
# Ключ "R" -- рекурсивный обход дерева каталогов.
# Ключ "F" -- добавляет дополнительные метки к именам файлов (к именам каталогов добавдяет оконечный символ /).
echo "Создано оглавление."

# Создать iso-образ.
mkisofs -r -o $IMAGFILE $IMAGE_DIRECTORY
echo "Создан iso-образ файловой системы ISO9660 ($IMAGEFILE)."

# "Прожигание" CDR.
cdrecord -v -isosize speed=$SPEED dev=0,0 $IMAGEFILE
echo "Запись диска."
echo "Наберитесь терпения, это может потребовать некоторого времени."

exit 0
cat, tac
cat -- это акроним от concatenate, выводит содержимое списка файлов на stdout. Для объединения файлов в один файл может использоваться в комбинации с операциями перенаправления (> или >>).

cat filename cat file.1 file.2 file.3 > file.123
Ключ -n, команды cat, вставляет порядковые номера строк в выходном файле. Ключ -b -- нумерут только не пустые строки. Ключ -v выводит непечатаемые символы в нотации с символом ^. Ключ -s заменяет несколько пустых строк, идущих подряд, одной пустой строкой.

см. также Пример 12-21 and Пример 12-17.

tac -- выводит содержимое файлов в обратном порядке, от последней строки к первой.

rev
выводит все строки файла задом наперед на stdout. Это не то же самое, что tac. Команда rev сохраняет порядок следования строк, но переворачивает каждую строку задом наперед.

bash$ cat file1.txt
Это строка 1.
 Это строка 2.


bash$ tac file1.txt
Это строка 2.
 Это строка 1.


bash$ rev file1.txt
.1 акортс отЭ
 .2 акортс отЭ
             


cp
Команда копирования файлов. cp file1 file2 скопирует file1 в file2, перезаписав file2 если он уже существовал (см. Пример 12-5).

Tip	
С флагами -a и -r, или -R выполняет копирование дерева каталогов.

mv
Команда перемещения файла. Эквивалентна комбинации команд cp и rm. Может использоваться для перемещения большого количества файлов или для переименования каталогов. Примеры использования команды mv вы найдете в Пример 9-17 и Пример A-3.

Note	
При использовании в неинтерактивных сценариях, команде mv следует передавать ключ -f, чтобы подавить запрос подтверждения на перемещение.

Если в качестве каталога назначения указан существующий каталог, то перемещаемый каталог становится подкаталогом каталога назначения..

bash$ mv source_directory target_directory

bash$ ls -lF target_directory
total 1
 drwxrwxr-x    2 bozo  bozo      1024 May 28 19:20 source_directory/
             


rm
Удаляет (remove) файл(ы). Ключ -f позволяет удалять даже файлы ТОЛЬКО-ДЛЯ-ЧТЕНИЯ и подавляет запрос подтверждения на удаление.

Warning	
С ключом -r, удаляет все файлы в подкаталогах.

rmdir
Удаляет каталог. Удаляемый каталог не должен содержать файлов, включая "скрытые файлы", [1] иначе каталог не будет удален.

mkdir
Создает новый каталог. mkdir -p project/programs/December создает каталог с заданным именем в требуемом каталоге. Ключ -p позволяет создавать промежуточные родительские каталоги.

chmod
Изменяет атрибуты существующего файла (см. Пример 11-10).

chmod +x filename
# Делает файл "filename" доступным для исполнения всем пользователям.

chmod u+s filename
# Устанавливается бит "suid" для "filename".
# В результате, любой пользователь сможет запустить "filename" с привилегиями владельца файла.
# (Это не относится к файлам-сценариям на языке командной оболочки.)


chmod 644 filename
# Выдает право на запись/чтение владельцу файла "filename", и право на чтение
# всем остальным
# (восьмеричное число).


chmod 1777 directory-name
# Выдает право на чтение, запись и исполнение файлов в каталоге,
# дополнительно устанавливает "sticky bit".
# Это означает, что удалять файлы в этом каталоге могут только владельцы файлов,
# владелец каталога и, само собой разумеется, root.


chattr
Изменяет атрибуты файла. Эта команда подобна команде chmod, за исключением синтаксиса вызова, и работает исключительно в файловой системе ext2.

ln
Создает ссылку на существующий файл. Чаще всего используется с ключом -s, что означает символическую, или "мягкую" (symbolic или "soft") ссылку. Позволяет задавать несколько имен одному и тому же файлу и превосходная альтернатива "псевдонимам" (алиасам) (см. Пример 4-6).

ln -s oldfile newfile создает ссылку, с именем newfile, на существующий файл oldfile, .

man, info
Команды доступа к справочным и информационным страницам по системным командам и установленным программам и утилитам. Как правило, страницы info содержат более подробную информацию, чем man.

Примечания

[1]	
Скрытыми считаются файлы, имена которых начинаются с точки, например, ~/.Xdefaults. Такие файлы не выводятся простой командой ls, и не могут быть удалены командой rm -rf *. Как правило, скрытыми делаются конфигурационные файлы в домашнем каталоге пользователя.

12.2. Более сложные команды

Команды для более опытных пользователей

find
-exec COMMAND \;

Для каждого найденного файла, соответствующего заданному шаблону поиска, выполняет команду COMMAND. Командная строка должна завершаться последовательностью символов \; (здесь символ ";" экранирован обратным слэшем, чтобы информировать командную оболочку о том, что символ ";" должен быть передан команде find как обычный символ). Если COMMAND содержит {}, то find подставляет полное имя найденного файла вместо "{}".

bash$ find ~/ -name '*.txt'
/home/bozo/.kde/share/apps/karm/karmdata.txt
/home/bozo/misc/irmeyc.txt
/home/bozo/test-scripts/1.txt
             


find /home/bozo/projects -mtime 1
#  Найти все файлы в каталоге /home/bozo/projects и вложенных подкаталогах,
#+ которые изменялись в течение последних суток.
#
#  mtime = время последнего изменения файла
#  ctime = время последнего изменения атрибутов файла (через 'chmod' или как-то иначе)
#  atime = время последнего обращения к файлу

DIR=/home/bozo/junk_files
find "$DIR" -type f -atime +5 -exec rm {} \;
#  Удалить все файлы в каталоге "/home/bozo/junk_files"
#+ к которым не было обращений в течение последних 5 дней.
#
#  "-type filetype", где
#  f = обычный файл
#  d = каталог, и т.п.
#  (Полный список ключей вы найдете в 'man find'.)


find /etc -exec grep '[0-9][0-9]*[.][0-9][0-9]*[.][0-9][0-9]*[.][0-9][0-9]*' {} \;

# Поиск всех IP-адресов (xxx.xxx.xxx.xxx) в файлах каталога  /etc.
# Однако эта команда выводит не только IP-адреса, как этого избежать?

# Примерно так:

find /etc -type f -exec cat '{}' \; | tr -c '.[:digit:]' '\n' \
 | grep '^[^.][^.]*\.[^.][^.]*\.[^.][^.]*\.[^.][^.]*$'
# [:digit:] -- один из символьных классов
# введен в стандарт POSIX 1003.2.

# Спасибо S.C.


Note	
Не следует путать опцию -exec команды find с внутренней командой Bash -- exec.

Пример 12-2. Badname, удаление файлов в текущем каталоге, имена которых содержат недопустимые символы и пробелы.

#!/bin/bash

# Удаление файлов в текущем каталоге, чьи имена содержат недопустимые символы.

for filename in *
do
badname=`echo "$filename" | sed -n /[\+\{\;\"\\\=\?~\(\)\<\>\&\*\|\$]/p`
# Недопустимые символы в именах файлов:     + { ; " \ = ? ~ ( ) < > & * | $
rm $badname 2>/dev/null    # Сообщения об ошибках "выстреливаются" в никуда.
done

# Теперь "позаботимся" о файлах, чьи имена содержат пробельные символы.
find . -name "* *" -exec rm -f {} \;
# На место "{}", find подставит полное имя файла.
# Символ '\' указывает на то, что ';' интерпретируется как обычный символ, а не как конец команды.

exit 0

#---------------------------------------------------------------------
# Строки, приведенные ниже, не будут выполнены, т.к. выше стоит команда "exit".

# Альтернативный вариант сценария:
find . -name '*[+{;"\\=?~()<>&*|$ ]*' -exec rm -f '{}' \;
exit 0
# (Спасибо S.C.)
Пример 12-3. Удаление файла по его номеру inode

#!/bin/bash
# idelete.sh: Удаление файла по номеру inode.

#  Этот прием используется в тех случаях, когда имя файла начинается с недопустимого символа,
#+ например, ? или -.

ARGCOUNT=1                      # Имя файла должно быть передано в сценарий.
E_WRONGARGS=70
E_FILE_NOT_EXIST=71
E_CHANGED_MIND=72

if [ $# -ne "$ARGCOUNT" ]
then
  echo "Порядок использования: `basename $0` filename"
  exit $E_WRONGARGS
fi

if [ ! -e "$1" ]
then
  echo "Файл \""$1"\" не найден."
  exit $E_FILE_NOT_EXIST
fi

inum=`ls -i | grep "$1" | awk '{print $1}'`
# inum = номер inode (index node) файла
# Каждый файл имеет свой inode, где хранится информация о физическом расположении файла.

echo; echo -n "Вы совершенно уверены в том, что желаете удалить \"$1\" (y/n)? "
# Ключ '-v' в команде 'rm' тоже заставит команду вывести подобный запрос.
read answer
case "$answer" in
[nN]) echo "Передумали?"
      exit $E_CHANGED_MIND
      ;;
*)    echo "Удаление файла \"$1\".";;
esac

find . -inum $inum -exec rm {} \;
echo "Файл "\"$1"\" удален!"

exit 0
Дополнительные примеры по использованию команды find вы найдете в Пример 12-22, Пример 3-4 и Пример 10-9. В страницах справочного ркуоводства (man find) вы найдете более подробную информацию об этой достаточно сложной и мощной команде.

xargs
Команда передачи аргументов указанной команде. Она разбивает поток аргументов на отдельные составляющие и поочередно передает их заданной команде для обработки. Эта команда может рассматриваться как мощная замена обратным одиничным кавычкам. Зачастую, когда команды, заключенные в обратные одиночные кавычки, завершаются с ошибкой too many arguments (слишком много аргументов), использование xargs позволяет обойти это ограничение. Обычно, xargs считывает список аргументов со стандартного устройства ввода stdin или из канала (конвейера), но может считывать информацию и из файла.

Если команда не задана, то по-умолчанию выполняется echo. При передаче аргументов по конвейеру, xargs допускает наличие пробельных символов и символов перевода строки, которые затем автоматически отбрасываются.

bash$ ls -l
total 0
-rw-rw-r--    1 bozo  bozo         0 Jan 29 23:58 file1
-rw-rw-r--    1 bozo  bozo         0 Jan 29 23:58 file2


bash$ ls -l | xargs
total 0 -rw-rw-r-- 1 bozo bozo 0 Jan 29 23:58 file1 -rw-rw-r-- 1 bozo bozo 0 Jan 29 23:58 file2
             


ls | xargs -p -l gzip -- упакует с помощью gzip все файлы в текущем каталоге, выводя запрос на подтверждение для каждого файла.

Tip	
xargs имеет очень любопытный ключ -n NN, который ограничивает количество передаваемых аргументов за один "присест" числом NN.

ls | xargs -n 8 echo -- выведет список файлов текущего каталога в 8 колонок.

Tip	
Еще одна полезная опция -- -0, в комбинации с find -print0 или grep -lZ позволяет обрабатывать аргументы, содержащие пробелы и кавычки.

find / -type f -print0 | xargs -0 grep -liwZ GUI | xargs -0 rm -f

grep -rliwZ GUI / | xargs -0 rm -f

Обе вышеприведенные команды удалят все файлы, содержащие в своем имени комбинацию символов "GUI". (Спасибо S.C.)

Пример 12-4. Использование команды xargs для мониторинга системного журнала

#!/bin/bash

# Создание временного файла мониторинга в текщем каталоге,
# куда переписываются несколько последних строк из /var/log/messages.

# Обратите внимание: если сценарий запускается обычным пользователем,
# то файл /var/log/messages должен быть доступен на чтение этому пользователю.
#         #root chmod 644 /var/log/messages

LINES=5

( date; uname -a ) >>logfile
# Время и информация о системе
echo --------------------------------------------------------------------- >>logfile
tail -$LINES /var/log/messages | xargs |  fmt -s >>logfile
echo >>logfile
echo >>logfile

exit 0

# Упражнение:
# --------
#  Измените сценарий таким образом, чтобы он мог отслеживать изменения в /var/log/messages
#+ с интервалом в 20 минут.
#  Подсказка: воспользуйтесь командой "watch".
Пример 12-5. copydir, копирование файлов из текущего каталога в другое место, с помощью xargs

#!/bin/bash

# Копирует все файлы из текущего каталога
# в каталог, указанный в командной строке.

if [ -z "$1" ]   # Выход, если каталог назначения не задан.
then
  echo "Порядок использования: `basename $0` directory-to-copy-to"
  exit 65
fi

ls . | xargs -i -t cp ./{} $1
# Этот сценария является точным эквивалентом
#    cp * $1
# если в именах файлов не содержатся пробельные символы.

exit 0
expr
Универсальный обработчик выражений: вычисляет заданное выражение (аргументы должны отделяться пробелами). Выражения могут быть арифметическими, логическими или строковыми.

expr 3 + 5
возвратит 8

expr 5 % 3
возвратит 2

expr 5 \* 3
возвратит 15

В арифметических выражениях, оператор умножения обязательно должен экранироваться обратным слэшем.

y=`expr $y + 1`
Операция инкремента переменной, то же самое, что и let y=y+1, или y=$(($y+1)). Пример подстановки арифметических выражений.

z=`expr substr $string $position $length`
Извлекает подстроку длиной $length символов, начиная с позиции $position.

Пример 12-6. Пример работы с expr

#!/bin/bash

# Демонстрация некоторых приемов работы с командой 'expr'
# =======================================

echo

# Арифметические операции
# -------------- --------

echo "Арифметические операции"
echo
a=`expr 5 + 3`
echo "5 + 3 = $a"

a=`expr $a + 1`
echo
echo "a + 1 = $a"
echo "(инкремент переменной)"

a=`expr 5 % 3`
# остаток от деления (деление по модулю)
echo
echo "5 mod 3 = $a"

echo
echo

# Логические операции
# ---------- --------

#  Возвращает 1 если выражение истинноо, 0 -- если ложно,
#+ в противоположность соглашениям, принятым в Bash.

echo "Логические операции"
echo

x=24
y=25
b=`expr $x = $y`         # Сравнение.
echo "b = $b"            # 0  ( $x -ne $y )
echo

a=3
b=`expr $a \> 10`
echo 'b=`expr $a \> 10`, поэтому...'
echo "Если a > 10, то b = 0 (ложь)"
echo "b = $b"            # 0  ( 3 ! -gt 10 )
echo

b=`expr $a \< 10`
echo "Если a < 10, то b = 1 (истина)"
echo "b = $b"            # 1  ( 3 -lt 10 )
echo
# Обратите внимание на необходимость экранирования операторов.

b=`expr $a \<= 3`
echo "Если a <= 3, то b = 1 (истина)"
echo "b = $b"            # 1  ( 3 -le 3 )
# Существует еще оператор "\>=" (больше или равно).


echo
echo

# Операции сравнения
# -------- ---------

echo "Операции сравнения"
echo
a=zipper
echo "a is $a"
if [ `expr $a = snap` ]
then
   echo "a -- это не zipper"
fi

echo
echo



# Операции со строками
# -------- -- --------

echo "Операции со строками"
echo

a=1234zipper43231
echo "Строка над которой производятся операции: \"$a\"."

# length: длина строки
b=`expr length $a`
echo "длина строки \"$a\" равна $b."

# index: позиция первого символа подстроки в строке
b=`expr index $a 23`
echo "Позиция первого символа \"2\" в строке \"$a\" : \"$b\"."

# substr: извлечение подстроки, начиная с заданной позиции, указанной длины
b=`expr substr $a 2 6`
echo "Подстрока в строке \"$a\", начиная с позиции 2,\
и длиной в 6 символов: \"$b\"."


#  При выполнении поиска по шаблону, по-умолчанию поиск
#+ начинается с ***начала*** строки.
#
#        Использование регулярных выражений
b=`expr match "$a" '[0-9]*'`               #  Подсчет количества цифр.
echo Количество цифр с начала строки \"$a\" : $b.
b=`expr match "$a" '\([0-9]*\)'`           #  Обратите внимание на экранирование круглых скобок
#                   ==      ==
echo "Цифры, стоящие в начале строки \"$a\" : \"$b\"."

echo

exit 0
Important	
Вместо оператора match можно использовать оператор :. Например, команда b=`expr $a : [0-9]*` является точным эквивалентом для b=`expr match $a [0-9]*` в примере, рассмотренном выше.

#!/bin/bash

echo
echo "Операции над строками с использованием конструкции \"expr \$string : \" "
echo "========================================================================"
echo

a=1234zipper5FLIPPER43231

echo "Строка, над которой выполняются операции: \"`expr "$a" : '\(.*\)'`\"."
#     Экранирование круглых скобок в шаблоне                    ==  ==


#  Если скобки не экранировать...
#+ то 'expr' преобразует строковый операнд в целое число.

echo "Длина строки \"$a\" равна `expr "$a" : '.*'`."   # Длина строки

echo "Количество цифр с начала строки \"$a\" равно `expr "$a" : '[0-9]*'`."

# ------------------------------------------------------------------------- #

echo

echo "Цифры, стоящие в начале строки \"$a\" : `expr "$a" : '\([0-9]*\)'`."
#                                                             ==      ==
echo "Первые 7 символов в строке \"$a\" : `expr "$a" : '\(.......\)'`."
#     ======                                          ==       ==
# Опять же, необходимо экранировать круглые скобки в шаблоне.
#
echo "Последние 7 символов в строке \"$a\" : `expr "$a" : '.*\(.......\)'`."
#     =========                  оператор конца строки     ^^
#  (фактически означает переход через любое количество символов, пока
#+  не будет найдена требуемая подстрока)

echo

exit 0


Этот пример демонстрирует необходимость экранирования оператора группировки -- \( ... \) в регулярных выражениях, при поиске по шаблону командой expr.

Perl, sed и awk имеют в своем распоряжении более мощный аппарат анализа строк. Коротенький скрипт на sed или awk, внутри сценария (см. Section 33.2) -- значительно более привлекательная альтернатива использованию expr при анализе строк.

Дополнительные примеры, по обработке строк, вы найдете в Section 9.2.

12.3. Команды для работы с датой и временем

Время/дата и измерение интервалов времени

date
Команда date без параметров выводит дату и время на стандартное устройство вывода stdout. Она становится гораздо интереснее при использовании дополнительных ключей форматирования вывода.

Пример 12-7. Команда date

#!/bin/bash
# Примеры использования команды 'date'

echo "Количество дней, прошедших с начала года: `date +%j`."
# Символ '+' обязателен при использовании форматирующего аргумента
# %j,  возвращающего количество дней, прошедших с начала года.

echo "Количество секунд, прошедших с 01/01/1970 : `date +%s`."
#  %s количество секунд, прошедших с начала "эпохи UNIX",
#+ но насколько этот ключ полезен?

prefix=temp
suffix=`eval date +%s`  # Ключ "+%s" характерен для GNU-версии 'date'.
filename=$prefix.$suffix
echo $filename
#  Прекрасный способ получения "уникального" имени для временного файла,
#+ даже лучше, чем с использованием $$.

# Дополнительную информацию вы найдете в 'man date'.

exit 0
Ключ -u дает UTC время (Universal Coordinated Time -- время по Гринвичу).

bash$ date
Fri Mar 29 21:07:39 MST 2002


bash$ date -u
Sat Mar 30 04:07:42 UTC 2002
             


zdump
Отображает время для указанной временной зоны.

bash$ zdump EST
EST  Tue Sep 18 22:09:22 2001 EST
             


time
Выводит подробную статистику по исполнению некоторой команды.

time ls -l / даст нечто подобное:

0.00user 0.01system 0:00.05elapsed 16%CPU (0avgtext+0avgdata 0maxresident)k
 0inputs+0outputs (149major+27minor)pagefaults 0swaps


См. так же очень похожую команду times, обсуждавшуюся в предыдущем разделе.

Note	
Начиная с версии 2.0 Bash, команда time стала зарезервированным словом интерпретатора, с несколько измененным поведением в конвейере.

touch
Утилита устанавливает время последнего обращения/изменения файла в текущее системное время или в заданное время, но так же может использоваться для создания нового пустого файла. Команда touch zzz создаст новый пустой файл с именем zzz, если перед этим файл zzz отсутствовал. Кроме того, такие пустые файлы могут использоваться для индикации, например, времени последнего изменения в проекте.

Note	
Эквивалентом команды touch могут служить : >> newfile или >> newfile (для обычных файлов).

at
Команда at -- используется для запуска заданий в заданное время. В общих чертах она напоминает crond, однако, at используется для однократного запуска набора команд.

at 2pm January 15 -- попросит ввести набор команд, которые необходимо запустить в указанное время. Эти команды должны быть совместимыми со сценариями командной оболочки. Ввод завершается нажатием комбинации клавиш Ctl-D.

Ключ -f или операция перенаправления ввода (<), заставляет at прочитать список команд из файла. Этот файл должен представлять из себя обычный сценарий, на языке командной оболочки и, само собой разумеется, такой сценарий должен быть неинтерактивным. Может использоваться совместно с командой run-parts для запуска различных наборов сценариев.

bash$ at 2:30 am Friday < at-jobs.list
job 2 at 2000-10-27 02:30
             


batch
Команда batch, управляющая запуском заданий, напоминает команду at, но запускает список команд только тогда, когда загруженность системы упадет ниже .8. Подобно команде at, с ключом -f, может считывать набор команд из файла.

cal
Выводит на stdout аккуратно отформатированный календарь на текущий месяц. Может выводить календарь за определенный год.

sleep
Приостанавливает исполнение сценария на заданное количество секунд, ничего не делая. Может использоваться для синхронизации процессов, запущенных в фоне, проверяя наступление ожидаемого события так часто, как это необходимо. Например, Пример 29-6.

sleep 3
# Пауза, длительностью в 3 секунды.


Note	
Команда sleep по-умолчанию принимает количество секунд, но ей можно передать и количество часов и минут и даже дней.

sleep 3 h
# Приостановка на 3 часа!


Note	
Для запуска команд через заданные интервалы времени лучше использовать watch .

usleep
Microsleep (здесь символ "u" должен читаться как буква греческого алфавита -- "мю", или префикс микро). Это то же самое, что и sleep, только интервал времени задается в микросекундах. Может использоваться для очень тонкой синхронизации процессов.

usleep 30
# Приостановка на 30 микросекунд.


Эта команда является частью пакета initscripts/rc-scripts в дистрибутиве Red Hat.

Caution	
Команда usleep не обеспечивает особую точность соблюдения интервалов, и поэтому она не подходит для применений, критичных ко времени.

hwclock, clock
Команда hwclock используется для получения доступа или коррекции аппаратных часов компьютера. С некоторыми ключами требует наличия привилегий root. Сенарий /etc/rc.d/rc.sysinit использует команду hwclock для установки системного времени во время загрузки.

Команда clock -- это синоним команды hwclock.

12.4. Команды обработки текста

sort
Сортирует содержимое файла, часто используется как промежуточный фильтр в конвейерах. Эта команда сортирует поток текста в порядке убывания или возрастания, в зависимости от заданных опций. Ключ -m используется для сортировки и объединения входных файлов. В странице info перечислено большое количество возможных вариантов ключей. См. Пример 10-9, Пример 10-10 и Пример A-9.

tsort
Топологическая сортировка, считывает пары строк, разделенных пробельными символами, и выполняет сортировку, в зависимости от заданного шаблона.

uniq
Удаляет повторяющиеся строки из отсортированного файла. Эту команду часто можно встретить в конвейере с командой sort.

cat list-1 list-2 list-3 | sort | uniq > final.list
# Содержимое файлов,
# сортируется,
# затем удаляются повторяющиеся строки,
# и результат записывается в выходной файл.


Ключ -c выводит количество повторяющихся строк.

bash$ cat testfile
Эта строка встречается только один раз.
Эта строка встречается дважды.
Эта строка встречается дважды.
Эта строка встречается трижды.
Эта строка встречается трижды.
Эта строка встречается трижды.


bash$ uniq -c testfile
1 Эта строка встречается только один раз.
2 Эта строка встречается дважды.
3 Эта строка встречается трижды.


bash$ sort testfile | uniq -c | sort -nr
3 Эта строка встречается трижды.
2 Эта строка встречается дважды.
1 Эта строка встречается только один раз.
             


Команда sort INPUTFILE | uniq -c | sort -nr выводит статистику встречаемости строк в файле INPUTFILE (ключ -nr, в команде sort, означает сортировку в порядке убывания). Этот шаблон может с успехом использоваться при анализе файлов системного журнала, словарей и везде, где необходимо проанализировать лексическую структуру документа.

Пример 12-8. Частота встречаемости отдельных слов

#!/bin/bash
# wf.sh: "Сырой" анализ частоты встречаемости слова в текстовом файле.


ARGS=1
E_BADARGS=65
E_NOFILE=66

if [ $# -ne "$ARGS" ]  # Файл для анализа задан?
then
  echo "Порядок использования: `basename $0` filename"
  exit $E_BADARGS
fi

if [ ! -f "$1" ]       # Проверка существования файла.
then
  echo "Файл \"$1\" не найден."
  exit $E_NOFILE
fi



########################################################
# main ()
sed -e 's/\.//g'  -e 's/ /\
/g' "$1" | tr 'A-Z' 'a-z' | sort | uniq -c | sort -nr
#                           =========================
#                         Подсчет количества вхождений

#  Точки и пробелы заменяются
#+ символами перевода строки,
#+ затем символы переводятся в нижний регистр
#+ и наконец подсчитывается количество вхождений,
#+ и выполняется сортировка по числу вхождений.
########################################################

# Упражнения:
# ---------
# 1) Добавьте команду 'sed' для отсечения других знаков пунктуации, например, запятых.
# 2) Добавьте удаление лишних пробелов и других пробельных символов.
# 3) Добавьте дополнительную сортировку так, чтобы слова с одинаковой частотой встречаемости
#+   сортировались бы в алфавитном порядке.

exit 0
bash$ cat testfile
Эта строка встречается только один раз.
Эта строка встречается дважды.
Эта строка встречается дважды.
Эта строка встречается трижды.
Эта строка встречается трижды.
Эта строка встречается трижды.


bash$ ./wf.sh testfile
       6 Эта
       6 встречается
       6 строка
       3 трижды
       2 дважды
       1 только
       1 один
       1 раз
                         
              


expand, unexpand
Команда expand преобразует символы табуляции в пробелы. Часто используется в конвейерной обработке текста.

Команда unexpand преобразует пробелы в символы табуляции. Т.е. она является обратной по отношению к команде expand.

cut
Предназначена для извлечения отдельных полей из текстовых файлов. Напоминает команду print $N в awk, но более ограничена в своих возможностях. В простейших случаях может быть неплохой заменой awk в сценариях. Особую значимость, для команды cut, представляют ключи -d (разделитель полей) и -f (номер(а) поля(ей)).

Использование команды cut для получения списка смонтированных файловых систем:

cat /etc/mtab | cut -d ' ' -f1,2


Использование команды cut для получения версии ОС и ядра:

uname -a | cut -d" " -f1,3,11,12


Использование команды cut для извлечения заголовков сообщений из электронных писем:

bash$ grep '^Subject:' read-messages | cut -c10-80
Re: Linux suitable for mission-critical apps?
 MAKE MILLIONS WORKING AT HOME3
 Spam complaint
 Re: Spam complaint


Использование команды cut при разборе текстового файла:

# Список пользователей в /etc/passwd.

FILENAME=/etc/passwd

for user in $(cut -d: -f1 $FILENAME)
do
  echo $user
done

# Спсибо Oleg Philon за этот пример.


cut -d ' ' -f2,3 filename эквивалентно awk -F'[ ]' '{ print $2, $3 }' filename

См. также Пример 12-33.

paste
Используется для объединения нескольких файлов в один многоколоночный файл.

join
Может рассматриваться как команда, родственная команде paste. Эта мощная утилита позволяет объединять два файла по общему полю, что представляет собой упрощенную версию реляционной базы данных.

Команда join оперирует только двумя файлами и объедияет только те строки, которые имеют общее поле (обычно числовое), результат объединения выводится на stdout. Объединяемые файлы должны быть отсортированы по ключевому полю.

File: 1.data

100 Shoes
200 Laces
300 Socks


File: 2.data

100 $40.00
200 $1.00
300 $2.00


bash$ join 1.data 2.data
File: 1.data 2.data

100 Shoes $40.00
200 Laces $1.00
300 Socks $2.00
             


Note	
На выходе ключевое поле встречается только один раз.

head
Выводит начальные строки из файла на stdout (по-умолчанию -- 10 строк, но это число можно задать иным). Эта команда имеет ряд интересных ключей.

Пример 12-9. Какие из файлов являются сценариями?

#!/bin/bash
# script-detector.sh: Отыскивает файлы сценариев в каталоге.

TESTCHARS=2    # Проверяются первые два символа.
SHABANG='#!'   # Сценарии как правило начинаются с "sha-bang."

for file in *  # Обход всех файлов в каталоге.
do
  if [[ `head -c$TESTCHARS "$file"` = "$SHABANG" ]]
  #      head -c2                      #!
  #  Ключ '-c' в команде "head" выводит заданное
  #+ количество символов, а не строк.
  then
    echo "Файл \"$file\" -- сценарий."
  else
    echo "Файл \"$file\" не является сценарием."
  fi
done
  
exit 0
Пример 12-10. Генератор 10-значных случайных чисел

#!/bin/bash
# rnd.sh: Генератор 10-значных случайных чисел

# Автор: Stephane Chazelas.

head -c4 /dev/urandom | od -N4 -tu4 | sed -ne '1s/.* //p'


# =================================================================== #

# Описание
# --------

# head:
# -c4 -- первые 4 байта.

# od:
# -N4 ограничивает вывод 4-мя байтами.
# -tu4 беззнаковый десятичный формат вывода.

# sed:
# -n, в комбинации с флагом "p", в команде "s",
# выводит только совпадающие с шаблоном строки.



# Автор сценария описывает действия 'sed' таким образом:

# head -c4 /dev/urandom | od -N4 -tu4 | sed -ne '1s/.* //p'
# ----------------------------------> |

# Передает вывод в "sed"    --------> |
# пусть это будет 0000000 1198195154\n

# sed начинает читать символы: 0000000 1198195154\n.
# Здесь он находит символ перевода строки,
# таким образом он получает строку (0000000 1198195154).
# Затем он просматривает <диапазон><действие>. Первый и единственный -- это

#   диапазон  действие
#   1         s/.* //p

# Номер строки попадает в заданный лиапазон, так что теперь он приступает к выполнению действия:
# пытается заменить наибольшую подстроку, заканчивающуюся пробелом
# ("0000000 ") "ничем" (//), и если замена произведена -- выводит результат
# ("p" -- это флаг команды "s", а не команда "p", которая имеет иное значение).

# теперь sed готов продолжить чтение входного потока. (Обратите внимание:
# если опустить ключ -n, то sed выведет строку еще раз)

# Теперь sed дочитывает остаток строки.
# Он готов приступить к анализу 2-й строки (которая отмечена '$'
# как последняя).
# Поскольку строка не попадает в заданный <диапазон>, на этом обработка прекращается.

# Проще говоря, команда sed означает:
# "В первой строке удалить любые символы, вплоть до последнего встреченного пробела,
# и затем вывести остаток."

# Сделать это можно более простым способом:
#           sed -e 's/.* //;q'

# Где, заданы два <диапазона><действия> (можно записать и по другому
#           sed -e 's/.* //' -e q):

#   диапазон                          действие
#   ничего (для совпадающих строк)    s/.* //
#   ничего (для совпадающих строк)    q (quit)

# Здесь sed считывает только первую строку.
# Выполняет оба действия, и выводит строку перед завершением
# (действие "q"), поскольку ключ "-n" опущен.

# =================================================================== #

# Простая альтернатива:
#           head -c4 /dev/urandom| od -An -tu4

exit 0
См. также Пример 12-30.

tail
Выводит последние строки из файла на stdout (по-умолчанию -- 10 строк). Обычно используется для мониторинга системных журналов. Ключ -f, позволяет вести непрерывное наблюдение за добавляемыми строками в файл.

Пример 12-11. Мониторинг системного журнала с помощью tail

#!/bin/bash

filename=sys.log

cat /dev/null > $filename; echo "Создание / очистка временного файла."
#  Если файл отсутствует, то он создается,
#+ и очищается, если существует.
#  : > filename   и   > filename дают тот же эффект.

tail /var/log/messages > $filename
# Файл /var/log/messages должен быть доступен для чтения.

echo "В файл $filename записаны последние строки из /var/log/messages."

exit 0
См. также Пример 12-4, Пример 12-30 и Пример 29-6.

grep
Многоцелевая поисковая утилита, использующая регулярные выражения. Изначально это была команда в древнем строчном редакторе ed, g/re/p, что означает -- global - regular expression - print.

grep pattern [file...]

Поиск участков текста в файле(ах), соответствующих шаблону pattern, где pattern может быть как обычной строкой, так и регулярным выражением.

bash$ grep '[rst]ystem.$' osinfo.txt
The GPL governs the distribution of the Linux operating system.
             


Если файл(ы) для поиска не задан, то команда grep работает как фильтр для устройства stdout, например в конвейере.

bash$ ps ax | grep clock
765 tty1     S      0:00 xclock
 901 pts/1    S      0:00 grep clock
             


-i -- выполняется поиск без учета регистра символов.

-w -- поиск совпадений целого слова.

-l -- вывод только имен файлов, в которых найдены участки, совпадающие с заданным образцом/шаблоном, без вывода совпадающих строк.

-r -- (рекурсивный поиск) поиск выполняется в текущем каталоге и всех вложенных подкаталогах.

The -n option lists the matching lines, together with line numbers.

bash$ grep -n Linux osinfo.txt
2:This is a file containing information about Linux.
 6:The GPL governs the distribution of the Linux operating system.
             


-v (или --invert-match) -- выводит только строки, не содержащие совпадений.

grep pattern1 *.txt | grep -v pattern2

# Выводятся строки из "*.txt", совпадающие с "pattern1",
# но ***не*** совпадающие с "pattern2".


-c (--count) -- выводит количество совпадений без вывода самих совпадений.

grep -c txt *.sgml   # (количество совпадений с "txt" в "*.sgml" файлах)


#   grep -cz .
#            ^ точка
# означает подсчет (-c) непустых ("." -- содержащих хотя бы один символ) элементов,
# разделенных нулевыми байтами (-z)
#
printf 'a b\nc  d\n\n\n\n\n\000\n\000e\000\000\nf' | grep -cz .     # 4
printf 'a b\nc  d\n\n\n\n\n\000\n\000e\000\000\nf' | grep -cz '$'   # 5
printf 'a b\nc  d\n\n\n\n\n\000\n\000e\000\000\nf' | grep -cz '^'   # 5
#
printf 'a b\nc  d\n\n\n\n\n\000\n\000e\000\000\nf' | grep -c '$'    # 9
# По-умолчанию, в качестве разделителя, принимается символ перевода строки (\n).

# Обратите внимание: ключ -z характерен для GNU-версии "grep".


# Спасибо S.C.


Если grep вызывается для поиска по группе файлов, то вывод будет содержать указание на имена файлов, в которых найдены совпадения.

bash$ grep Linux osinfo.txt misc.txt
osinfo.txt:This is a file containing information about Linux.
 osinfo.txt:The GPL governs the distribution of the Linux operating system.
 misc.txt:The Linux operating system is steadily gaining in popularity.
             


Tip	
Для того, чтобы заставить grep выводить имя файла, когда поиск производится по одному-единственному файлу, достаточно указать устройство /dev/null в качестве второго файла.

bash$ grep Linux osinfo.txt /dev/null
osinfo.txt:This is a file containing information about Linux.
 osinfo.txt:The GPL governs the distribution of the Linux operating system.
             


Если совпадение было найдено, то grep возвращает код завершения -- 0, это может оказаться полезным при выполнении поиска в условных операторах ( в таких случаях особый интерес может представлять ключ -q, который подавляет вывод).

SUCCESS=0                      # если найдено совпадение
word=Linux
filename=data.file

grep -q "$word" "$filename"    # "-q" -- подавляет вывод на stdout.

if [ $? -eq $SUCCESS ]
then
  echo "Образец $word найден в $filename"
else
  echo "Образец $word в файле $filename не найден"
fi


Пример 29-6 -- пример поиска заданного образца в системном журнале, с помощью grep.

Пример 12-12. Сценарий-эмулятор "grep"

#!/bin/bash
# grp.sh: Очень "грубая" реализация 'grep'.

E_BADARGS=65

if [ -z "$1" ]    # Проверка наличия аргументов.
then
  echo "Порядок использования: `basename $0` pattern"
  exit $E_BADARGS
fi

echo

for file in *     # Обход всех файлов в $PWD.
do
  output=$(sed -n /"$1"/p $file)  # Подстановка команд.

  if [ ! -z "$output" ]           # Что произойдет, если кавычки вокруг "$output" убрать?
  then
    echo -n "$file: "
    echo $output
  fi              #  эквивалент: sed -ne "/$1/s|^|${file}: |p"

  echo
done

echo

exit 0

# Упражнения:
# ---------
# 1) Добавьте вывод символов перевода строки, если найдено более одного совпадения в любом из файлов.
# 2) Добавьте обработку различных ключей.
Note	
egrep -- то же самое, что и grep -E. Эта команда использует несколько отличающийся, расширенный набор регулярных выражений, что позволяет выполнять поиск более гибко.

fgrep -- то же самое, что и grep -F. Эта команда выполняет поиск строк символов (не регулярных выражений), что несколько увеличивает скорость поиска.

Утилита agrep имеет более широкие возможности поиска приблизительных совпадений. Образец поиска может отличаться от найденной строки на указанное число символов.

Tip	
Для поиска по сжатым файлам следует использовать утилиты zgrep, zegrep или zfgrep. Они с успехом могут использоваться и для не сжатых файлов, но в этом случае они уступают в скорости обычным grep, egrep и fgrep. Они очень удобны при выполнении поиска по смешенному набору файлов -- когда одни файлы сжаты, а другие нет.

Для поиска по bzip-файлам используйте bzgrep.

look
Команда look очень похожа на grep, и предназначена для поиска по "словарям" -- отсортированным файлам. По-умолчанию, поиск выполняется в файле /usr/dict/words, но может быть указан и другой словарь.

Пример 12-13. Поиск слов в словаре

#!/bin/bash
# lookup: Выполняется поиск каждого слова из файла в словаре.

file=words.data  # Файл с искомыми словами.

echo

while [ "$word" != end ]  # Последнее слово в файле.
do
  read word      # Из файла, потому, что выполнено перенаправление в конце цикла.
  look $word > /dev/null  # Подавление вывода строк из словаря.
  lookup=$?      # Код возврата команды 'look'.

  if [ "$lookup" -eq 0 ]
  then
    echo "Слово \"$word\" найдено."
  else
    echo "Слово \"$word\" не найдено."
  fi

done <"$file"    # Перенаправление ввода из файла $file, так что "чтение" производится оттуда.

echo

exit 0

# ----------------------------------------------------------------
# Строки, расположенные ниже не будут исполнены, поскольку выше стоит команда "exit".


# Stephane Chazelas предложил более короткий вариант:

while read word && [[ $word != end ]]
do if look "$word" > /dev/null
   then echo "Слово \"$word\" найдено."
   else echo "Слово \"$word\" не найдено."
   fi
done <"$file"

exit 0
sed, awk
Скриптовые языки, специально разработанные для анализа текстовых данных.

sed
Неинтерактивный "потоковый редактор". Широко используется в сценариях на языке командной оболочки.

awk
Утилита контекстного поиска и преобразования текста, замечательный инструмент для извлечения и/или обработки полей (колонок) в структурированных текстовых файлах. Синтаксис awk напоминает язык C.

wc
wc -- "word count", счетчик слов в файле или в потоке:

bash $ wc /usr/doc/sed-3.02/README
20     127     838 /usr/doc/sed-3.02/README
[20 строк  127 слов  838 символов]


wc -w подсчитывает только слова.

wc -l подсчитывает только строки.

wc -c подсчитывает только символы.

wc -L возвращает длину наибольшей строки.

Подсчет количества .txt-файлов в текущем каталоге с помощью wc:

$ ls *.txt | wc -l
# Эта команда будет работать, если ни в одном из имен файлов "*.txt" нет символа перевода строки.

# Альтернативный вариант:
#      find . -maxdepth 1 -name \*.txt -print0 | grep -cz .
#      (shopt -s nullglob; set -- *.txt; echo $#)

# Спасибо S.C.


Подсчет общего размера файлов, чьи имена начинаются с символов, в диапазоне d - h

bash$ wc [d-h]* | grep total | awk '{print $3}'
71832
             


От переводчика: в случае, если у вас локаль отлична от "C", то вышеприведенная команда может не дать результата, поскольку wc вернет не слово "total", в конце вывода, а "итого". Тогда можно попробовать несколько измененный вариант:

bash$ wc [d-h]* | grep итого | awk '{print $3}'
71832
             


Использование wc для подсчета количества вхождений слова "Linux" в основной исходный файл с текстом этого руководства.

bash$ grep Linux abs-book.sgml | wc -l
50
             


См. также Пример 12-30 и Пример 16-7.

Отдельные команды располагают функциональностью wc в виде своих ключей.

... | grep foo | wc -l
# Часто встречающаяся конструкция, которая может быть сокращена.

... | grep -c foo
# Ключ "-c" ("--count") команды grep.

# Спасибо S.C.


tr
Замена одних символов на другие.

Caution	
В отдельных случаях символы необходимо заключать в кавычки и/или квадратные скобки. Кавычки предотвращают интерпретацию специальных символов командной оболочкой. Квадратные скобки должны заключаться в кавычки.

Команда tr "A-Z" "*" <filename или tr A-Z \* <filename заменяет все символы верхнего регистра в filename на звездочки (вывод производится на stdout). В некоторых системах этот вариант может оказаться неработоспособным, тогда попробуйте tr A-Z '[**]'.

Ключ -d удаляет символы из заданного диапазона.

echo "abcdef"                 # abcdef
echo "abcdef" | tr -d b-d     # aef


tr -d 0-9 <filename
# Удалит все цифровые символы из файла "filename".


Ключ --squeeze-repeats (-s) удалит все повторяющиеся последовательности символов. Может использоваться для удаления лишних пробельных символов.

bash$ echo "XXXXX" | tr --squeeze-repeats 'X'
X


Ключ -c "complement" заменит символы в соответствии с шаблоном. Этот ключ воздействует только на те символы, которые НЕ соответствуют заданному шаблону.

bash$ echo "acfdeb123" | tr -c b-d +
+c+d+b++++


Обратите внимание: команда tr корректно распознает символьные классы POSIX. [1]

bash$ echo "abcd2ef1" | tr '[:alpha:]' -
----2--1
             


Пример 12-14. toupper: Преобразование символов в верхний регистр.

#!/bin/bash
# Преобразование символов в верхний регистр.

E_BADARGS=65

if [ -z "$1" ]  # Стандартная проверка командной строки.
then
  echo "Порядок использования: `basename $0` filename"
  exit $E_BADARGS
fi

tr a-z A-Z <"$1"

# Тот же эффект можно получить при использовании символьных классов POSIX:
#        tr '[:lower:]' '[:upper:]' <"$1"
# Спасибо S.C.

exit 0
Пример 12-15. lowercase: Изменение имен всех файлов в текущем каталоге в нижний регистр.

#! /bin/bash
#
# Изменит все имена файлов в текущем каталоге в нижнй регистр.
#


for filename in *                # Обход всех файлов в каталоге.
do
   fname=`basename $filename`
   n=`echo $fname | tr A-Z a-z`  # Перевести символы в нижний регистр.
   if [ "$fname" != "$n" ]       # Переименовать только те файлы, имена которых изменились.
   then
     mv $fname $n
   fi
done

exit 0


# Сироки приведенные ниже не будут исполняться, поскольку выше стоит команда "exit".
#--------------------------------------------------------#
# Запустите эту часть сценария, удалив строки , стоящие выше.

# Сценарий, приведенный выше, не работает с именами файлов, содержащими пробелы или символы перевода строки.

# В связи с этим, Stephane Chazelas предложил следующий вариант:


for filename in *    # Нет необходимости использовать basename,
                     # поскольку "*" возвращает имена, не содержащие "/".
do n=`echo "$filename/" | tr '[:upper:]' '[:lower:]'`
#                             символьные классы POSIX.
#                    Завершающий слэш добавлен для того, чтобы символ перевода строки
#                    не был удален при подстановке команды.
   # Подстановка переменной:
   n=${n%/}          # Удаление завершающего слэша, добавленного выше.
   [[ $filename == $n ]] || mv "$filename" "$n"
                     # Проверка -- действительно ли изменилось имя файла.
done

exit 0
Пример 12-16. du: Преобразование текстового файла из формата DOS в формат UNIX.

#!/bin/bash
# du.sh: Преобразование текстового файла из формата DOS в формат UNIX.

E_WRONGARGS=65

if [ -z "$1" ]
then
  echo "Порядок использования: `basename $0` filename-to-convert"
  exit $E_WRONGARGS
fi

NEWFILENAME=$1.unx

CR='\015'  # Возврат каретки.
# Строки в текстовых файлах DOS завершаются комбинацией символов CR-LF.

tr -d $CR < $1 > $NEWFILENAME
# Удалить символы CR и записать в новый файл.

echo "Исходный текстовый файл: \"$1\"."
echo "Преобразованный файл: \"$NEWFILENAME\"."

exit 0
Пример 12-17. rot13: Сверхслабое шифрование по алгоритму rot13.

#!/bin/bash
# rot13.sh: Классический алгоритм шифрования rot13,
#           который способен "расколоть" даже 3-х летний ребенок.

# Порядок использования: ./rot13.sh filename
# или                    ./rot13.sh <filename
# или                    ./rot13.sh и ввести текст с клавиатуры (stdin)

cat "$@" | tr 'a-zA-Z' 'n-za-mN-ZA-M'   # "a" заменяется на "n", "b" на "o", и т.д.
#  Конструкция 'cat "$@"'
#+ позволяет вводить данные как со stdin, так и из файла.

exit 0
Пример 12-18. Более "сложный" шифр

#!/bin/bash
# crypto-quote.sh: Ограниченное шифрование

# Шифрование ограничивается простой заменой одних алфавитных символов другими.
#  Результат очень похож на шифры-загадки


key=ETAOINSHRDLUBCFGJMQPVWZYXK
# Здесь, "key" -- ни что иное, как "перемешанный" алфавит.
# Изменение ключа "key" приведет к изменению шифра.

# Конструкция 'cat "$@"' позволяет вводить данные как со stdin, так и из файла.
# Если используется stdin, то ввод должен завершаться комбинацией Control-D.
# Иначе,  в командной строке, сценарию должно быть передано имя файла.

cat "$@" |  tr "a-z" "A-Z"   | tr "A-Z" "$key"
#        | в верхний регистр |    шифрование
# Такой прием позволяет шифровать как символы в верхнем регистре, так и в нижнем.
# Неалфавитные символы остаются без изменений.


# Попробуйте зашифровать какой либо текст, например
# "Nothing so needs reforming as other people's habits."
# --Mark Twain
#
# Результат будет:
# "CFPHRCS QF CIIOQ MINFMBRCS EQ FPHIM GIFGUI'Q HETRPQ."
# --BEML PZERC

# Для дешифрации можно использовать следующую комбинацию:
# cat "$@" | tr "$key" "A-Z"


#  Этот нехитрый шифр может быть "взломан" 12-ти летним ребенком
#+ с помощью карандаша и бумаги.

exit 0
Различные версии tr

Утилита tr имеет две, исторически сложившиеся, версии. BSD-версия не использует квадратные скобки (tr a-z A-Z), в то время как SysV-версия использует их (tr '[a-z]' '[A-Z]'). GNU-версия утилиты tr напоминает версию BSD, но диапазоны символов обязательно должны заключаться в квадратные скобки.

fold
Выравнивает текст по ширине, разрывая, если это необходимо, слова. Особый интерес представляет ключ -s, который производит перенос строк по пробелам, стараясь не разрывать слова. (см. Пример 12-19 и Пример A-2).

fmt
Очень простая утилита форматирования текста, чаще всего используемая как фильтр в конвейерах для того, чтобы выполнить "перенос" длинных строк текста.

Пример 12-19. Отформатированный список файлов.

#!/bin/bash

WIDTH=40                    # 40 символов в строке.

b=`ls /usr/local/bin`       # Получить список файлов...

echo $b | fmt -w $WIDTH

# То же самое можно выполнить командой
#  echo $b | fold - -s -w $WIDTH
 
exit 0
См. также Пример 12-4.

Tip	
Очень мощной альтернативой утилите fmt, является утилита par (автор Kamil Toman), которую вы сможете найти на http://www.cs.berkeley.edu/~amc/Par/.

col
Эта утилита с обманчивым названием удаляет из входного потока символы обратной подачи бумаги (код ESC 7). Она так же пытается заменить пробелы на табуляции. Основная область применения утилиты col -- фильтрация вывода отдельных утилит обработки текста, таких как groff и tbl.

column
Форматирование по столбцам. Эта утилита преобразует текст, например какой либо список, в табличное, более "удобочитаемое", представление, вставляя символы табуляции по мере необходимости.

Пример 12-20. Пример форматирования списка файлов в каталоге

#!/bin/bash
# За основу сценария взят пример "man column".


(printf "PERMISSIONS LINKS OWNER GROUP SIZE DATE TIME PROG-NAME\n" \
; ls -l | sed 1d) | column -t

#  Команда "sed 1d" удаляет первую строку, выводимую командой ls,
#+ (для локали "С" это строка:  "total        N",
#+ где "N" -- общее количество файлов.

# Ключ -t, команды "column", означает "табличное" представление.

exit 0
colrm
Утилита удаления колонок. Удаляет колонки (столбцы) сиволов из файла и выводит результат на stdout. colrm 2 4 <filename -- удалит символы со 2-го по 4-й включительно, в каждой строке в файле filename.

Warning	
Если файл содержит символы табуляции или непечатаемые символы, то результат может получиться самым неожиданным. В таких случаях, как правило, утилиту colrm, в конвейере, окружают командами expand и unexpand.

nl
Нумерует строки в файле. nl filename -- выведет файл filename на stdout, и в начале каждой строки вставит ее порядковый номер, счет начинается с первой непустой строки. Если файл не указывается, то принимается ввод со stdin.

Вывод команды nl очень напоминает cat -n, однако, по-умолчанию nl не нумерует пустые строки.

Пример 12-21. nl: Самонумерующийся сценарий.

#!/bin/bash

# Сценарий выводит себя сам на stdout дважды, нумеруя строки сценария.

# 'nl' вставит для этой строки номер 3, поскольку она не нумерует пустые строки.
# 'cat -n' вставит для этой строки номер 5.

nl `basename $0`

echo; echo  # А теперь попробуем вывести текст сценария с помощью 'cat -n'

cat -n `basename $0`
# Различия состоят в том, что 'cat -n' нумерует все строки.
# Обратите внимание: 'nl -ba' -- сделает то же самое.

exit 0
pr
Подготовка файла к печати. Утилита производит разбивку файла на страницы, приводя его в вид пригодный для печати или для вывода на экран. Разнообразные ключи позволяют выполнять различные манипуляции над строками и колонками, соединять строки, устанавливать поля, нумеровать строки, добавлять колонтитулы и многое, многое другое. Утилита pr соединяет в себе функциональность таких команд, как nl, paste, fold, column и expand.

pr -o 5 --width=65 fileZZZ | more -- выдаст хорошо оформленное и разбитое на страницы содержимое файла fileZZZ.

Хочу особо отметить ключ -d, который выводит строки с двойным интервалом (тот же эффект, что и sed -G).

gettext
GNU утилита, предназначена для нужд локализации и перевода сообщений программ, выводимых на экран, на язык пользователя. Не смотря на то, что это актуально, прежде всего, для программ на языке C, тем не менее gettext с успехом может использоваться в сценариях командной оболочки для тех же целей. См. info page.

iconv
Утилита преобразования текста из одной кодировки в другую. В основном используется для нужд локализации.

recode
Может рассматриваться как разновилность утилиты iconv, описанной выше. Универсальная утилита для преобразования текстовой информации в различные кодировки.

TeX, gs
TeX и Postscript -- языки разметки текста, используемые для подготовки текста к печати или выводу на экран.

TeX -- это сложная система подготовки к печати, разработанная Дональдом Кнутом (Donald Knuth). Эту утилиту удобнее использовать внутри сценария, чем в командной строке, поскольку в сценарии проще один раз записать все необходимые параметры, передаваемые утилите, для получения необходимого результата.

Ghostscript (gs) -- это GPL-версия интерпретатора Postscript.

groff, tbl, eqn
groff -- это еще один язык разметки текста и форматированного вывода. Является расширенной GNU-версией пакета roff/troff в UNIX-системах.

tbl -- утилита обработки таблиц, должна рассматриваться как составная часть groff, так как ее задачей является преобразование таблиц в команды groff.

eqn -- утилита преобразования математических выражений в команды groff.

lex, yacc
lex -- утилита лексического разбора текста. В Linux-системах заменена на свободно распространяемую утилиту flex.

yacc -- утилита для создания синтаксических анализаторов, на основе набора грамматик, задаваемых разработчиком. В Linux-системах, эта утилита заменена на свободно распространяемую утилиту bison.

Примечания

[1]	
Это верно только для GNU-версии команды tr, поведение этой команды, в коммерческих UNIX-системах, может несколько отличаться.

12.5. Команды для работы с файлами и архивами

Архивация

tar
Стандартная, для UNIX, утилита архивирования. Первоначально -- это была программа Tape ARchiving, которая впоследствии переросла в универсальный пакет, который может работать с любыми типами устройств (см. Пример 3-4). В GNU-версию tar была добавлена возможность одновременно производить сжатие tar-архива, например команда tar czvf archive_name.tar.gz * создает tar-архив дерева подкаталогов и вызывает gzip для выполнения сжатия, исключение составляют скрытые файлы в текущем каталоге ($PWD). [1]

Некоторые, часто используемые, ключи команды tar:

-c -- создать (create) новый архив

-x -- извлечь (extract) файлы из архива

--delete -- удалить (delete) файлы из архива

Caution	
Этот ключ игнорируется для накопителей на магнитной ленте.

-r -- добавить (append) файлы в существующий архив

-A -- добавить (append) tar-файлы в существующий архив

-t -- список файлов в архиве (содержимое архива)

-u -- обновить (update) архив

-d -- операция сравнения архива с заданной файловой системой

-z -- обработка архива с помощью gzip

(Сжатие или разжатие, в зависимости от комбинации сопутствующих ключей -c или -x)

-j -- обработка архива с помошью bzip2



Caution	
При восстановлении "битых" tar.gz архивов могут возникнуть определенные сложности, поэтому делайте несколько резервных копий.

shar
Утилита создания shell-архива. Архивируемые файлы объединяются в единый файл без выполнения сжатия, в результате получается архив -- по сути полноценный сценарий на языке командной оболочки, начинающийся со строки #!/bin/sh, который содержит полный набор команд, необходимый для разархивирования. Такого рода архивы до сих пор можно найти в некоторых телеконференциях в Internet, но в последнее время они активно вытесняются связкой tar/gzip. Для распаковки shar-архивов предназначена команда unshar.

ar
Утилита создания и обслуживания архивов, главным образом применяется к двоичным файлам библиотек.

rpm
Red Hat Package Manager, или rpm -- набор утилит, предназначенных для построения и обслуживания пакетов программного обеспечения как в исходном коде, так и в собранном (откомпилированном) виде. Среди всего прочего, включает в себя утилиты, производящие установку ПО, проверку зависимостей пакетов и проверку их целостности.

Самый простой вариант установки ПО из rpm -- выполнить команду rpm -i package_name.rpm.

Tip	
Команда rpm -qa выдаст полный список всех установленных rpm-пакетов в данной системе. Команда rpm -qa package_name выведет только пакет(ы) с именем, содержащим комбинацию символов package_name.

bash$ rpm -qa
redhat-logos-1.1.3-1
 glibc-2.2.4-13
 cracklib-2.7-12
 dosfstools-2.7-1
 gdbm-1.8.0-10
 ksymoops-2.4.1-1
 mktemp-1.5-11
 perl-5.6.0-17
 reiserfs-utils-3.x.0j-2
 ...


bash$ rpm -qa docbook-utils
docbook-utils-0.6.9-2


bash$ rpm -qa docbook | grep docbook
docbook-dtd31-sgml-1.0-10
 docbook-style-dsssl-1.64-3
 docbook-dtd30-sgml-1.0-10
 docbook-dtd40-sgml-1.0-11
 docbook-utils-pdf-0.6.9-2
 docbook-dtd41-sgml-1.0-10
 docbook-utils-0.6.9-2
             


cpio
Специализированная утилита архивации и копирования (copy input and output). Используется все реже и реже, поскольку вытесняется более мощным архиватором tar/gzip. Наиболее употребительна для таких операций, как перемещение дерева каталогов.

Пример 12-22. Пример перемещения дерева каталогов с помощью cpio

#!/bin/bash

# Копирование дерева каталогов с помощью cpio.

ARGS=2
E_BADARGS=65

if [ $# -ne "$ARGS" ]
then
  echo "Порядок использования: `basename $0` source destination"
  exit $E_BADARGS
fi

source=$1
destination=$2

find "$source" -depth | cpio -admvp "$destination"
# Информацию по ключам утилиты cpio вы найдете в страницах руководства "man cpio".

exit 0
rpm2cpio
Эта утилита конвертирует rpm-пакет в архив cpio.

Пример 12-23. Распаковка архива rpm

#!/bin/bash
# de-rpm.sh: Распаковка архива 'rpm'

: ${1?"Порядок использования: `basename $0` target-file"}
# Сценарию должно быть передано имя архива 'rpm'.


TEMPFILE=$$.cpio                         # Временный файл с "уникальным" именем.
                                         # $$ -- PID процесса сценария.

rpm2cpio < $1 > $TEMPFILE                # Конверсия из rpm в cpio.
cpio --make-directories -F $TEMPFILE -i  # Рапсковка cpio-архива.
rm -f $TEMPFILE                          # Удаление cpio-архива.

exit 0

#  Упражнение:
#  Добавьте проверку на: 1) Существование "target-file"
#+                       2) Действительно ли "target-file" является rpm-архивом.
#  Подсказка:               используйте комсанду 'file'.
Сжатие

gzip
Стандартная GNU/UNIX утилита сжатия, заменившая более слабую, и к тому же проприетарную, утилиту compress. Соответствующая утилита декомпрессии (разжатия) -- gunzip, которая является эквивалентом команды gzip -d.

Для работы со сжатыми файлами в конвейере используется фильтр zcat, который выводит результат своей работы на stdout, допускает перенаправление вывода. Фактически это та же команда cat, только приспособленная для работы со сжатыми файлами (включая файлы, сжатые утилитой compress). Эквивалент команды zcat -- gzip -dc.

Caution	
В некоторых коммерческих версиях UNIX, команда zcat является синонимом команды uncompress -c, и не может работать с файлами, сжатыми с помощью gzip.

См. также Пример 7-7.

bzip2
Альтернативная утилита сжатия, обычно дает более высокую степень сжатия (но при этом работает медленнее), чем gzip, особенно это проявляется на больших файлах. Соответствующая утилита декомпрессии -- bunzip2.

Note	
В современные версии tar добавлена поддержка bzip2.

compress, uncompress
Устаревшие проприетарные утилиты для работы с архивами, входящие в состав некоторых коммерческих дистрибутивов UNIX. В последнее время вытесняются более мощной утилитой gzip. Linux-дистрибутивы, как правило, включают в свой состав эти утилиты для обратной совместимости, однако gunzip корректно разархивирует файлы, обработанные с помощью compress.

Tip	
Утилита znew предназначена для преобразования compress-архивов в gzip-архивы.

sq
Еще одна утилита-фильтр сжатия, которая обслуживает только отсортированные списки слов. Использует стандартный, для фильтров, синтаксис вызова -- sq < input-file > output-file. Быстрая, но не такая эффективная как gzip. Соответствующая ей утилита декомпрессии называется unsq, синтаксис вызова аналогичен утилите sq.

Tip	
Вывод от sq может быть передан по конвейеру утилите gzip, для дальнейшего сжатия.

zip, unzip
Кроссплатформенная утилита архивирования и сжатия, совместимая, по формату архивного файла, с утилитой DOS -- pkzip.exe. "Zip"-архивы, по-моему, более приемлемый вариант для обмена данными через Internet, чем "tarballs" (тарболлы, или tar-архивы).

unarc, unarj, unrar
Этот набор утилит предназначен для распаковки архивов, созданных с помощью DOS архиваторов -- arc.exe, arj.exe и rar.exe.

Получение сведений о файлах

file
Утилита идентификации файлов. Команда file file-name верне тип файла file-name, например, ascii text или data. Для этого она анализирует сигнатуру, или магическое число и сопоставляет ее со списком известных сигнатур из /usr/share/magic, /etc/magic или /usr/lib/magic (в зависимости от дистрибутива Linux/UNIX).

-f -- ключ пакетного режима работы утилиты file, в этом случае утилита принимает список анализируемых имен файлов из заданного файла. Ключ -z используется для анализа файлов в архиве.

bash$ file test.tar.gz
test.tar.gz: gzip compressed data, deflated, last modified: Sun Sep 16 13:34:51 2001, os: Unix

bash file -z test.tar.gz
test.tar.gz: GNU tar archive (gzip compressed data, deflated, last modified: Sun Sep 16 13:34:51 2001, os: Unix)
             


Пример 12-24. Удаление комментариев из файла с текстом программы на языке C

#!/bin/bash
# strip-comment.sh: Удаление комментариев (/* COMMENT */) из исходных текстов программ на языке C.

E_NOARGS=65
E_ARGERROR=66
E_WRONG_FILE_TYPE=67

if [ $# -eq "$E_NOARGS" ]
then
  echo "Порядок использования: `basename $0` C-program-file" >&2 # Вывод сообщения на stderr.
  exit $E_ARGERROR
fi

# Проверка типа файла.
type=`eval file $1 | awk '{ print $2, $3, $4, $5 }'`
# "file $1" -- выводит тип файла...
# затем awk удаляет первое поле -- имя файла...
# после этого результат записывается в переменную "type".
correct_type="ASCII C program text"

if [ "$type" != "$correct_type" ]
then
  echo
  echo "Этот сценарий работает только с исходными текстами программ на языке C."
  echo
  exit $E_WRONG_FILE_TYPE
fi


# Довольно замысловатый сценарий sed :
#--------
sed '
/^\/\*/d
/.*\/\*/d
' $1
#--------
# Если вы потратите несколько часов на изучение основ sed, то он станет немного понятнее.


#  Следовало бы добавить еще обработку
#+ комментариев, расположенных в одной строке с кодом.
#  Оставляю это вам, в качестве упражнения.

# Кроме того, этот сценарий удалит все строки, которые содержат комбинации символов "*/" или "/*",
# не всегда желаемый результат.

exit 0


# ----------------------------------------------------------------
# Строки, расположенные ниже не будут исполнены из-за стоящей выше команды 'exit 0'.

# Stephane Chazelas предложил другой, альтернативный вариант:

usage() {
  echo "Порядок использования: `basename $0` C-program-file" >&2
  exit 1
}

WEIRD=`echo -n -e '\377'`   # или WEIRD=$'\377'
[[ $# -eq 1 ]] || usage
case `file "$1"` in
  *"C program text"*) sed -e "s%/\*%${WEIRD}%g;s%\*/%${WEIRD}%g" "$1" \
     | tr '\377\n' '\n\377' \
     | sed -ne 'p;n' \
     | tr -d '\n' | tr '\377' '\n';;
  *) usage;;
esac

# Этот вариант, все еще некорректно обрабатывает такие строки как:
# printf("/*");
# или
# /*  /* ошибочный вложенный комментарий */
#
# Для обработки специальных случаев (\", \\" ...) придется написать синтаксический анализатор
# (может быть с помощью lex или yacc?).

exit 0
which
Команда which command-xxx вернет полный путь к "command-xxx". Очень полезна для того, чтобы узнать -- установлена ли та или иная утилита в системе.

$bash which rm

/usr/bin/rm


whereis
Очень похожа на which, упоминавшуюся выше. Команда whereis command-xxx вернет полный путь к "command-xxx", но кроме того, еще и путь к manpage -- файлу, странице справочника по заданной утилите.

$bash whereis rm

rm: /bin/rm /usr/share/man/man1/rm.1.bz2


whatis
Утилита whatis filexxx отыщет "filexxx" в своей базе данных. Может рассматриваться как упрощенный вариант команды man.

$bash whatis whatis

whatis               (1)  - search the whatis database for complete words


Пример 12-25. Исследование каталога /usr/X11R6/bin

#!/bin/bash

# Что находится в каталоге /usr/X11R6/bin?

DIRECTORY="/usr/X11R6/bin"
# Попробуйте также "/bin", "/usr/bin", "/usr/local/bin", и т.д.

for file in $DIRECTORY/*
do
  whatis `basename $file`   # Вывод информации о файле.
done

exit 0
# Вывод этого сценария можно перенаправить в файл:
# ./what.sh >>whatis.db
# или включить постраничный просмотр на экране,
# ./what.sh | less
См. также Пример 10-3.

vdir
Вывод списка файлов в каталоге. Тот же эффект имеет команда ls -l.

Это одна из утилит GNU fileutils.

bash$ vdir
total 10
 -rw-r--r--    1 bozo  bozo      4034 Jul 18 22:04 data1.xrolo
 -rw-r--r--    1 bozo  bozo      4602 May 25 13:58 data1.xrolo.bak
 -rw-r--r--    1 bozo  bozo       877 Dec 17  2000 employment.xrolo

bash ls -l
total 10
 -rw-r--r--    1 bozo  bozo      4034 Jul 18 22:04 data1.xrolo
 -rw-r--r--    1 bozo  bozo      4602 May 25 13:58 data1.xrolo.bak
 -rw-r--r--    1 bozo  bozo       877 Dec 17  2000 employment.xrolo
             


locate, slocate
Команда locate определяет местонахождение файла, используя свою базу данных, создаваемую специально для этих целей. Команда slocate -- это защищенная версия locate (которая может оказаться простым псевдонимом команды slocate).

$bash locate hickson

/usr/lib/xephem/catalogs/hickson.edb


readlink
Возвращает имя файла, на который указывает символическая ссылка.

bash$ readlink /usr/bin/awk
../../bin/gawk
             


strings
Команда strings используется для поиска печатаемых строк в двоичных файлах. Она выводит последовательности печатаемых символов, обнаруженных в заданном файле. Может использоваться для прикидочного анализа дамп-файлов (core dump) или для отыскания информации о типе файла, например для графических файлов неизвестного формата (например, strings image-file | more может вывести такую строчку: JFIF, что говорит о том, что мы имеем дело с графическим файлом в формате jpeg). В сценариях, вероятнее всего, вам придется использовать эту команду в связке с grep или sed. См. Пример 10-7 и Пример 10-9.

Пример 12-26. "Расширенная" команда strings

#!/bin/bash
# wstrings.sh: "word-strings" (расширенная команда "strings")
#
#  Этот сценарий фильтрует вывод команды "strings" путем проверки на соответствие
#+ выводимых слов по файлу словаря.
#  Таким способом эффективно "отсекается" весь "мусор",
#+ и выводятся только распознанные слова.

# =================================================================
#                 Стандартная проверка входных аргументов
ARGS=1
E_BADARGS=65
E_NOFILE=66

if [ $# -ne $ARGS ]
then
  echo "Порядок использования: `basename $0` filename"
  exit $E_BADARGS
fi

if [ ! -f "$1" ]                      # Проверка наличия файла.
then
    echo "Файл \"$1\" не найден."
    exit $E_NOFILE
fi
# =================================================================


MINSTRLEN=3                           #  Минимальная длина строки.
WORDFILE=/usr/share/dict/linux.words  #  Файл словаря.
                                      #  Можно указать иной
                                      #+ файл словаря
                                      #+ в формате -- "одно слово на строке".


wlist=`strings "$1" | tr A-Z a-z | tr '[:space:]' Z | \
tr -cs '[:alpha:]' Z | tr -s '\173-\377' Z | tr Z ' '`

# Трансляция вывода от 'strings' с помощью нескольких 'tr'.
#  "tr A-Z a-z"  -- перевод в нижний регистр.
#  "tr '[:space:]'"  -- конвертирует пробелы в символы Z.
#  "tr -cs '[:alpha:]' Z"  -- конвертирует неалфавитные символы в символы Z,
#+ и удаляет повторяющиеся символы Z.
#  "tr -s '\173-\377' Z"  -- Конвертирует все символы, с кодами выше 'z' в Z
#+ и удаляет повторяющиеся символы Z,
#+ эта команда удалит все символы, которые не были распознаны предыдущими
#+ командами трансляции (tr).
#  Наконец, "tr Z ' '" -- преобразует все символы Z в пробелы,
#+ которые будут рассматриваться в качестве разделителя слов в цикле, приведенном ниже.

#  Обратите внимание на технику многоуровневой обработки с помощью 'tr',
#+ каждый раз эта команда вызывается с различным набором аргументов.


for word in $wlist                    # Важно:
                                      # переменная $wlist не должна заключаться в кавычки.
                                      # "$wlist" -- не сработает.
                                      # Почему?
do

  strlen=${#word}                     # Дина строки.
  if [ "$strlen" -lt "$MINSTRLEN" ]   # Не рассматривать короткие строки.
  then
    continue
  fi

  grep -Fw $word "$WORDFILE"          # Проверка слова по словарю.

done


exit 0
Сравнение

diff, patch
diff: очень гибкая утилита сравнения файлов. Она выполняет построчное сравнение файлов. В отдельных случаях, таких как поиск по словарю, может оказаться полезной фильтрация файлов с помощью sort и uniq перед тем как отдать поток данных через конвейер утилите diff. diff file-1 file-2 -- выведет строки, имеющие отличия, указывая -- какому файлу, какая строка принадлежит.

С ключом --side-by-side, команда diff выведет сравниваемые файлы в две колонки, с указанием несовпадающих строк. Ключи -c и -u так же служат для облегчения интерпретации результатов работы diff.

Существует ряд интерфейсных оболочек для утилиты diff, среди них можно назвать: spiff, wdiff, xdiff и mgdiff.

Tip	
Команда diff возвращает код завершения 0, если сравниваемые файлы идентичны и 1, если они отличаются. Это позволяет использовать diff в условных операторах внутри сценариев на языке командной оболочки (см. ниже).

В общем случае, diff используется для генерации файла различий, который используется как аргумент команды patch. Ключ -e отвечает за вывод файла различий в формате, пригодном для использования с ed или ex.

patch: гибкая утилита для "наложения заплат". С помощью файла различий, сгенерированного утилитой diff, утилита patch может использоваться для обновления устаревших версий файлов. Это позволяет распространять относительно небольшие "diff"-файлы вместо целых пакетов. Распространение "заплат" к ядру стало наиболее предпочтительным методом распространения более новых версий ядра Linux.

patch -p1 <patch-file
# Применит все изменения из 'patch-file'
# к файлам, описанным там же.
# Так выполняется обновление пакетов до более высоких версий.


Наложение "заплат" на ядро:

cd /usr/src
gzip -cd patchXX.gz | patch -p0
# Обновление исходных текстов ядра с помощью 'patch'.
# Пример взят из файла "README",
# автор не известен (Alan Cox?).


Note	
Кроме того, утилита diff в состоянии выполнять рекурсивный обход каталогов.

bash$ diff -r ~/notes1 ~/notes2
Only in /home/bozo/notes1: file02
 Only in /home/bozo/notes1: file03
 Only in /home/bozo/notes2: file04
             


Tip	
Утилита zdiff сравнивает сжатые, с помощью gzip, файлы.

diff3
Расширенная версия diff, которая сравнивает сразу 3 файла. В случае успеха возвращает 0, но, к сожалению, не дает никакой информации о результатах сравнения.

bash$ diff3 file-1 file-2 file-3
====
 1:1c
   This is line 1 of "file-1".
 2:1c
   This is line 1 of "file-2".
 3:1c
   This is line 1 of "file-3"
             


sdiff
Сравнение и/или редактирование двух файлов перед объединением их в один файл. Это интерактивная утилита, по своей природе, и из-за этого она довольно редко используется в сценариях.

cmp
Утилита cmp -- это упрощенная версия diff. В то время, как diff выводит подробную информацию об имеющихся различиях, утилита cmp лишь показывет номер строки и позицию в строке, где было встречено различие.

Note	
Подобно команде diff, команда cmp возвращает код завершения 0, если файлы идентичны и 1, если они различны. Это позволяет использовать команду cmp в условных операторах.

Пример 12-27. Пример сравнения двух файлов с помощью cmp.

#!/bin/bash

ARGS=2  # Ожидаются два аргумента командной строки.
E_BADARGS=65
E_UNREADABLE=66

if [ $# -ne "$ARGS" ]
then
  echo "Порядок использования: `basename $0` file1 file2"
  exit $E_BADARGS
fi

if [[ ! -r "$1" || ! -r "$2" ]]
then
  echo "Оба файла должны существовать и должны быть доступны для чтения."
  exit $E_UNREADABLE
fi

cmp $1 $2 &> /dev/null  # /dev/null -- "похоронит" вывод от команды "cmp".
#   cmp -s $1 $2  даст тот же результат ("-s" -- флаг "тишины" для "cmp")
#   Спасибо Anders Gustavsson за замечание.
#
# Также применимо к 'diff', т.е.,   diff $1 $2 &> /dev/null

if [ $? -eq 0 ]         # Проверка кода возврата команды "cmp".
then
  echo "Файл \"$1\" идентичен файлу \"$2\"."
else
  echo "Файл \"$1\" отличается от файла \"$2\"."
fi

exit 0
Tip	
Для работы с gzip файлами используется утилита zcmp.

comm
Универсальная утилита сравнения. Работает с отсортированными файлами.

comm -options first-file second-file

comm file-1 file-2 -- вывод в три колонки:

колонка 1 = уникальные строки для file-1

колонка 2 = уникальные строки для file-2

колонка 3 = одинаковые строки.



Ключи, подавляющие вывод в одной или более колонках.

-1 -- подавление вывода в колонку 1

-2 -- подавление вывода в колонку 2

-3 -- подавление вывода в колонку 3

-12 -- подавление вывода в колонки 1 и 2, и т.д.



Утилиты

basename
Выводит только название файла, без каталога размещения. Конструкция basename $0 -- позволяет сценарию узнать свое имя, то есть имя файла, который был запущен. Это имя может быть использовано для вывода сообщений, напрмиер:

echo "Порядок использования: `basename $0` arg1 arg2 ... argn"


dirname
Отсекает basename от полного имени файла и выводит только путь к файлу.

Note	
Утилитам basename и dirname может быть передана любая строка, в качестве аргумента. Этот аргумент необязательно должен быть именем существующего файла (см. Пример A-8).

Пример 12-28. Утилиты basename и dirname

#!/bin/bash

a=/home/bozo/daily-journal.txt

echo "Basename для /home/bozo/daily-journal.txt = `basename $a`"
echo "Dirname для /home/bozo/daily-journal.txt = `dirname $a`"
echo
echo "Мой домашний каталог `basename ~/`."             # Можно указать просто ~.
echo "Каталог моего домашнего каталога `dirname ~/`."  # Можно указать просто ~.

exit 0
split
Утилита разбивает файл на несколько частей. Обычно используется для разбиения больших файлов, чтобы их можно было записать на дискеты или передать по электронной почте по частям.

sum, cksum, md5sum
Эти утилиты предназначены для вычисления контрольных сумм. Контрольная сумма -- это некоторое число, вычисляемое исходя из содержимого файла, и служит для контроля целостности информации в файле. Сценарий может выполнять проверку контрольных сумм для того, чтобы убедиться, что файл не был изменен или поврежден. Для большей безопасности, рекомендуется использовать 128-битную сумму, генерируемую утилитой md5sum (message digest checksum).

bash$ cksum /boot/vmlinuz
1670054224 804083 /boot/vmlinuz


bash$ md5sum /boot/vmlinuz
0f43eccea8f09e0a0b2b5cf1dcf333ba  /boot/vmlinuz
             


Обратите внимание: утилита cksum выводит контрольную сумму и размер файла в байтах.

Пример 12-29. Проверка целостности файла

#!/bin/bash
# file-integrity.sh: Проверка целостности файлов в заданном каталоге

E_DIR_NOMATCH=70
E_BAD_DBFILE=71

dbfile=File_record.md5
# Файл для хранения контрольных сумм.


set_up_database ()
{
  echo ""$directory"" > "$dbfile"
  # Записать название каталога в первую строку файла.
  md5sum "$directory"/* >> "$dbfile"
  # Записать контрольные суммы md5 и имена файлов.
}

check_database ()
{
  local n=0
  local filename
  local checksum

  # ------------------------------------------- #
  #  Возможно эта проверка и не нужна,
  #+ но лучше перестраховаться сейчас, чем жалеть об этом потом.

  if [ ! -r "$dbfile" ]
  then
    echo "Не могу прочитать файл с контрольными суммами!"
    exit $E_BAD_DBFILE
  fi
  # ------------------------------------------- #

  while read record[n]
  do

    directory_checked="${record[0]}"
    if [ "$directory_checked" != "$directory" ]
    then
      echo "Имя каталога не совпадает с записаным в файле!"
      # Попытка использовать файл контрольных сумм для другого каталога.
      exit $E_DIR_NOMATCH
    fi

    if [ "$n" -gt 0 ]   # Не имя каталога.
    then
      filename[n]=$( echo ${record[$n]} | awk '{ print $2 }' )
      #  md5sum записывает в обратном порядке,
      #+ сначала контрольную сумму, затем имя файла.
      checksum[n]=$( md5sum "${filename[n]}" )

      if [ "${record[n]}" = "${checksum[n]}" ]
      then
        echo "Файл ${filename[n]} не был изменен."
      else
        echo "ОШИБКА КОНТРОЛЬНОЙ СУММЫ для файла ${filename[n]}!"
        # Файл был изменен со времени последней проверки.
      fi

    fi


    let "n+=1"
  done <"$dbfile"       # Чтение контрольных сумм из файла.

}

# =================================================== #
# main ()

if [ -z  "$1" ]
then
  directory="$PWD"      #  Если каталог не задан,
else                    #+ то используется текущий каталог.
  directory="$1"
fi

clear                   # Очистка экрана.

# ------------------------------------------------------------------ #
  if [ ! -r "$dbfile" ] # Необходимо создать файл с контрольными суммами?
  then
    echo "Создание файла с контрольными суммами, \""$directory"/"$dbfile"\"."; echo
    set_up_database
  fi
# ------------------------------------------------------------------ #

check_database          # Выполнить проверку.

echo

#  Вывод этого сценария можно перенаправить в файл,
#+ это особенно полезно при проверке большого количества файлов.

#  Более строгая проверка целостности файлов,
#+ может быть выполнена с помощью пакета "Tripwire",
#+ http://sourceforge.net/projects/tripwire/.

exit 0
Более творческий подход к использованию md5sum вы нйдете в Пример A-21.

shred
Надежное, с точки зрения безопасности, стирание файла, посредством предварительной, многократной записи в файл случайной информации, перед тем как удалить его. Эта команда имеет тот же эффект, что и Пример 12-42, но делает это более изящным и безопасным способом.

Является составной частью пакета GNU fileutils.

Caution	
Имеется ряд технологий, с помощью которых все-таки возможно восстановить файлы, удаленные утилитой shred.

Кодирование и шифрование

uuencode
Эта утилита используется для кодирования двоичных файлов в символы ASCII, после такого кодирования файлы могут, с достаточной степенью безопасности, передаваться по сети, вкладываться в электронные письма и т.п..

uudecode
Утилита декодирования файлов, прошедших обработку утилитой uuencode.

Пример 12-30. Декодирование файлов

#!/bin/bash

lines=35        # 35 строк для заголовка (более чем достаточно).

for File in *   # Обход всех файлов в текущем каталоге...
do
  search1=`head -$lines $File | grep begin | wc -w`
  search2=`tail -$lines $File | grep end | wc -w`
  #  Закодированные файлы начинаются со слова "begin",
  #+ и заканчиваются словом "end".
  if [ "$search1" -gt 0 ]
  then
    if [ "$search2" -gt 0 ]
    then
      echo "декодируется файл - $File -"
      uudecode $File
    fi
  fi
done

#  Обратите внимание: если передать сценарию самого себя, для декодирования,
#+ то это введет его в заблуждение
#+ поскольку в тексте сценария встречаются слова "begin" и "end".

exit 0
Tip	
При декодировании и выводе длинных текстовых сообщений из новостных групп Usenet, очень нелишним будет передать текст, по конвейеру, команде fold -s.

mimencode, mmencode
Утилиты mimencode и mmencode предназначены для обработки закодированных мультимедийных вложений в электронные письма. Хотя почтовые программы (такие как pine или kmail) имеют возможность автоматической обработки таких вложений, тем не менее эти утилиты позволяют обрабатывать вложения вручную, из командной строки или в пакетном режиме, из сценария на языке командной оболочки.

crypt
Одно время, это была стандартная, для UNIX, утилита шифрования файлов. [2] Политически мотивированные, правительственные постановления ряда стран, напрямую запрещают экспорт программного обеспечения для шифрования, что, в результате, привело практически к полному исчезновению crypt из большинства UNIX-систем (в том числе и Linux). К счастью, программистами было разработано множество вполне приличных альтернатив, и среди них cruft (см. Пример A-5).

Прочее

mktemp
Создает временный файл с "уникальным" именем.

PREFIX=filename
tempfile=`mktemp $PREFIX.XXXXXX`
#                        ^^^^^^ Необходимо по меньшей мере 6 заполнителей
echo "имя временного файла = $tempfile"
# имя временного файла = filename.QA2ZpY
#                 или нечто подобное...


make
Утилита для компиляции и сборки программ. Но может использоваться для выполнения любых других операций, основанных на анализе наличия изменений в исходных файлах.

Команда make использует в своей работе Makefile, который содержит перечень зависимостей и операций, которые необходимо выполнить для удовлетворения этих зависимостей.

install
Своего рода -- утилита копирования файлов, похожа на cp, но дополнительно позволяет изменять права доступа и атрибуты копируемых файлов. Напрямую эта команда практически не используется, чаще всего она встречается в Makefile (в разделе make install :). Она может использоваться в сценариях установки ПО.

dos2unix
Автор утилиты -- Benjamin Lin со-товарищи. Предназначена для преобразования текстовых файлов из формата DOS (в котором строки завершаются комбинацией символов CR-LF) в формат UNIX (в котором строки завершаются одним символом LF) и обратно.

ptx
Команда ptx [targetfile] выводит a упорядоченный предметный указатель для targetfile, который можно обработать, по мере необходимости, какой либо утилитой форматирования, в конвейере.

more, less
Команды постраничного просмотра текстовых файлов или потоков на stdout. Могут использоваться в сценариях в качестве фильтров.

Примечания

[1]	
Команда tar czvf archive_name.tar.gz * включит в архив все скрытые файлы (имена которых начинаются с точки) из вложенных подкаталогов. Это недокументированная "особенность" GNU-версии tar.

[2]	
Она реализует алгоритм симметричного блочного шифрования, в противоположность алгоритмам шифрования с "открытым ключом", из которых широко известен pgp.

12.6. Команды для работы с сетью

Команды, описываемые в этом разделе, могут найти применение при исследовании и анализе процессов передачи данных по сети, а также могут использоваться в борьбе со спамерами.

Информация и статистика

host
Возвращает информацию об узле Интернета, по заданному имени или IP адресу, выполняя поиск с помощью службы DNS.

bash$ host surfacemail.com
surfacemail.com. has address 202.92.42.236
             


ipcalc
Производит поиск IP адреса. С ключом -h, ipcalc выполняет поиск имени хоста в DNS, по заданному IP адресу.

bash$ ipcalc -h 202.92.42.236
HOSTNAME=surfacemail.com
             


nslookup
Выполняет "поиск имени узла" Интернета по заданному IP адресу. По сути, эквивалентна командам ipcalc -h и dig -x. Команда может исполняться как в интерактивном, так и в неинтерактивном режиме, т.е. в пределах сценария.

bash$ nslookup -sil 66.97.104.180
nslookup kuhleersparnis.ch
 Server:         135.116.137.2
 Address:        135.116.137.2#53

 Non-authoritative answer:
 Name:   kuhleersparnis.ch
             


dig
Подобно команде nslookup, выполняет "поиск имени узла" в Интернете.

Сравните вывод команды dig -x с выводом команд ipcalc -h и nslookup.

bash$ dig -x 81.9.6.2
;; Got answer:
 ;; ->>HEADER<<- opcode: QUERY, status: NXDOMAIN, id: 11649
 ;; flags: qr rd ra; QUERY: 1, ANSWER: 0, AUTHORITY: 1, ADDITIONAL: 0

 ;; QUESTION SECTION:
 ;2.6.9.81.in-addr.arpa.         IN      PTR

 ;; AUTHORITY SECTION:
 6.9.81.in-addr.arpa.    3600    IN      SOA     ns.eltel.net. noc.eltel.net.
 2002031705 900 600 86400 3600

 ;; Query time: 537 msec
 ;; SERVER: 135.116.137.2#53(135.116.137.2)
 ;; WHEN: Wed Jun 26 08:35:24 2002
 ;; MSG SIZE  rcvd: 91
             


traceroute
Утилита предназначена для исследования топологии сети посредством передачи ICMP пакетов удаленному узлу. Эта программа может работать в LAN, WAN и в Интернет. Удаленный узел может быть указан как по имени, так и по IP адресу. Вывод команды traceroute может быть передан по конвейеру утилитам grep или sed, для дальнейшего анализа.

bash$ traceroute 81.9.6.2
traceroute to 81.9.6.2 (81.9.6.2), 30 hops max, 38 byte packets
 1  tc43.xjbnnbrb.com (136.30.178.8)  191.303 ms  179.400 ms  179.767 ms
 2  or0.xjbnnbrb.com (136.30.178.1)  179.536 ms  179.534 ms  169.685 ms
 3  192.168.11.101 (192.168.11.101)  189.471 ms  189.556 ms *
 ...
             


ping
Выполняет передачу пакета "ICMP ECHO_REQUEST" другой системе в сети. Чаще всего служит в качестве инструмента диагностики соединений, должна использоваться с большой осторожностью.

В случае успеха, ping возвращает код завершения 0, поэтому команда ping может использоваться в условных операторах.

bash$ ping localhost
PING localhost.localdomain (127.0.0.1) from 127.0.0.1 : 56(84) bytes of data.
 Warning: time of day goes back, taking countermeasures.
 64 bytes from localhost.localdomain (127.0.0.1): icmp_seq=0 ttl=255 time=709 usec
 64 bytes from localhost.localdomain (127.0.0.1): icmp_seq=1 ttl=255 time=286 usec

 --- localhost.localdomain ping statistics ---
 2 packets transmitted, 2 packets received, 0% packet loss
 round-trip min/avg/max/mdev = 0.286/0.497/0.709/0.212 ms
             


whois
Выполняет поиск в DNS (Domain Name System). Ключом -h можно указать какой из whois серверов будет запрошен. См. Пример 4-6.

finger
Возвращает информацию о пользователях в сети. По желанию, эта команда может выводить содержимое файлов ~/.plan, ~/.project и ~/.forward, указанного пользователя.

bash$ finger
Login  Name           Tty      Idle  Login Time   Office     Office Phone
 bozo   Bozo Bozeman   tty1        8  Jun 25 16:59
 bozo   Bozo Bozeman   ttyp0          Jun 25 16:59
 bozo   Bozo Bozeman   ttyp1          Jun 25 17:07



bash$ finger bozo
Login: bozo                             Name: Bozo Bozeman
 Directory: /home/bozo                   Shell: /bin/bash
 On since Fri Aug 31 20:13 (MST) on tty1    1 hour 38 minutes idle
 On since Fri Aug 31 20:13 (MST) on pts/0   12 seconds idle
 On since Fri Aug 31 20:13 (MST) on pts/1
 On since Fri Aug 31 20:31 (MST) on pts/2   1 hour 16 minutes idle
 No mail.
 No Plan.
             


По соображениям безопасности, в большинстве сетей служба finger, и соответствующий демон, отключена. [1]

vrfy
Проверка адреса электронной почты.

Доступ к удаленным системам

sx, rx
Команды sx и rx служат для приема/передачи файлов на/из удаленный узел в сети, по протоколу xmodem. Входят в состав пакета minicom.

sz, rz
Команды sz и rz служат для приема/передачи файлов на/из удаленный узел в сети, по протоколу zmodem. Протокол zmodem имеет некоторые преимущества перед протоколом xmodem, в качестве такого преимущества можно назвать более высокую скорость передачи и возможность возобновления передачи, в случае ее разрыва. Входят в состав пакета minicom.

ftp
Под этим именем подразумевается утилита и протокол передачи файлов. Сеансы ftp могут устанавливаться из сценариев (см. Пример 17-7, Пример A-5 и Пример A-14).

uucp
UNIX to UNIX copy. Это коммуникационный пакет для передачи файлов между UNIX серверами. Сценарий на языке командной оболочки -- один из самых эффективных способов автоматизации такого обмена.

Похоже, что с появлением Интернет и электронной почты, uucp постепенно уходит в небытие, однако, она с успехом может использоваться в изолированных, не имеющих выхода в Интернет, сетях.

cu
Call Up -- выполняет соединение с удаленной системой, как простой терминал. Эта команда является частью пакета uucp и, своего рода, упрощенным вариантом команды telnet.

telnet
Утилита и протокол для подключения к удаленной системе.

Caution	
Протокол telnet небезопасен по своей природе, поэтому следует воздерживаться от его использования.

wget
wget -- неинтерактивная утилита для скачивания файлов с Web или ftp сайтов.

wget -p http://www.xyz23.com/file01.html
wget -r ftp://ftp.xyz24.net/~bozo/project_files/ -o $SAVEFILE


lynx
lynx -- Web браузер, внутри сценариев (с ключом -dump) может использоваться для скачивания файлов с Web или ftp сайтов, в неинтерактивном режиме.

lynx -dump http://www.xyz23.com/file01.html >$SAVEFILE


rlogin
Remote login -- инициирует сессию с удаленной системой. Эта команда небезопасна, вместо нее лучше использовать ssh.

rsh
Remote shell -- исполняет команду на удаленной системе. Эта команда небезопасна, вместо нее лучше использовать ssh.

rcp
Remote copy -- копирование файлов между двумя машинами через сеть. Подобно прочим r* утилитам, команда rcp небезопасна и потому, использовать ее в сценариях нежелательно. В качестве замены можно порекомендовать ssh или expect.

ssh
Secure shell -- устанавливает сеанс связи и выполняет команды на удаленной системе. Выступает в качестве защищенной замены для telnet, rlogin, rcp и rsh. Использует идентификацию, аутентификацию и шифрование информации, передаваемой через сеть. Подробности вы найдете в man ssh.

Локальная сеть

write
Эта утилита позволяет передать текст сообщения на другой терминал (console или xterm). Разрешить или запретить доступ к терминалу можно с помощью команды mesg.

Поскольку команда write работает в интерактивном режиме, то, как правило, она не употребляется в сценариях.

Mail

mail
Чтение или передача электронной почты.

Этот почтовый клиент командной строки с успехом может использоваться в сценариях.

Пример 12-31. Сценарий, отправляющий себя самого по электронной почте

#!/bin/sh
# self-mailer.sh: Сценарий отправляет себя самого по электронной почте

adr=${1:-`whoami`}     # Если пользователь не указан, то -- себе самому.
#  Вызов 'self-mailer.sh wiseguy@superdupergenius.com'
#+ приведет к передаче электронного письма по указанному адресу.
#  Вызов 'self-mailer.sh' (без аргументов) -- отправит письмо
#+ пользователю, запустившему сценарий, например, bozo@localhost.localdomain.
#
#  Дополнительно о конструкции ${parameter:-default},
#+ см. раздел "Подстановка параметров"
#+ в главе "К вопросу о переменных".

# ============================================================================
  cat $0 | mail -s "Сценарий \"`basename $0`\" отправил себя сам." "$adr"
# ============================================================================

# --------------------------------------------
#  Поздравляю!
#  Этот сценарий запустила какая-то "редиска",
#+ и заставила отправить этот текст к Вам.
#  Очевидно кто-то не знает
#+ куда девать свое время.
# --------------------------------------------

echo "`date`, сценарий \"`basename $0`\" отправлен "$adr"."

exit 0
mailto
Команда mailto, похожа на mail, она также отправляет сообщения по электронной почте. Однако, кроме этого, mailto позволяет отправлять MIME (multimedia) сообщения.

vacation
Эта утилита предназначена для автоматической передачи ответов на электронные письма, например для того, чтобы уведомить отправителя о том, что получатель временно отсутствует. Работает совместно с sendmail и не может использоваться для передачи сообщений через коммутируемые линии (по модему).

Примечания

[1]	
Демон -- это некий фоновый процесс, не привязанный ни к одной из терминальных сессий. Демоны предназначены для выполнения определенного круга задач либо через заданные промежутки времени, либо по наступлению какого либо события.

Слово "демон" ("daemon"), в греческой мифологии, употреблялось для обозначения призраков, духов, чего-то мистического, сверхестественного. В мире UNIX -- под словом демон подразумевается процесс, который "тихо" и "незаметно" выполняет свою работу.

12.7. Команды управления терминалом

Команды, имеющие отношение к консоли или терминалу

tput
инициализация терминала или выполнение запроса к базе данных терминалов terminfo. С помощью tput можно выполнять различные операции. tput clear -- эквивалентно команде clear. tput reset -- эквивалентно команде reset. tput sgr0 -- так же сбрасывет настройки терминал, но без очистки экрана.

bash$ tput longname
xterm terminal emulator (XFree86 4.0 Window System)
             


Команда tput cup X Y перемещает курсор в координаты (X,Y). Обычно этой команде предшествует clear, очищающая экран.

Обратите внимание: stty предлагает более широкий диапазон возможностей.

infocmp
Cравнение или печать информации о характеристиках терминалов, хранящейся в базе данных terminfo.

bash$ infocmp
#       Reconstructed via infocmp from file:
 /usr/share/terminfo/r/rxvt
 rxvt|rxvt terminal emulator (X Window System),
         am, bce, eo, km, mir, msgr, xenl, xon,
         colors#8, cols#80, it#8, lines#24, pairs#64,
         acsc=``aaffggjjkkllmmnnooppqqrrssttuuvvwwxxyyzz{{||}}~~,
         bel=^G, blink=\E[5m, bold=\E[1m,
         civis=\E[?25l,
         clear=\E[H\E[2J, cnorm=\E[?25h, cr=^M,
         ...
             


reset
Сбрасывает настройки терминала и очищает экран. Как и в случае команды clear, курсор и приглашение к вводу (prompt) выводятся в верхнем левом углу терминала.

clear
Команда clear просто очищает экран терминала или окно xterm. Курсор и приглашение к вводу (prompt) выводятся в верхнем левом углу терминала. Эта команда может запускаться как из командной строки, так и из сценария. См. Пример 10-25.

script
Эта утилита позволяет сохранять в файле все символы, введенные пользователем c клавиатуры (вывод тоже). Получая, фактически, подробнейший синхронный протокол сессии.

8. Команды выполнения математических операций

factor
Разложение целого числа на простые множители.

bash$ factor 27417
27417: 3 13 19 37
             


bc
Bash не в состоянии выполнять действия над числами с плавающей запятой и не содержит многих важных математических функций. К счастью существует bc.

Универсальная, выполняющая вычисления с произвольной точностью, утилита bc обладает некоторыми возможностями, характерными для языков программирования.

Синтаксис bc немного напоминает язык C.

Поскольку это утилита UNIX, то она может достаточно широко использоваться в сценариях на языке командной оболочки, в том числе и в конвейерной обработке данных.

Ниже приводится простой шаблон работы с утилитой bc в сценарии. Здесь используется прием подстановки команд.

             variable=$(echo "OPTIONS; OPERATIONS" | bc)
             


Пример 12-32. Ежемесячные выплаты по займу

#!/bin/bash
# monthlypmt.sh: Расчет ежемесячных выплат по займу.


#  Это измененный вариант пакета "mcalc" (mortgage calculator),
#+ написанного Jeff Schmidt и Mendel Cooper (ваш покорный слуга).
#   http://www.ibiblio.org/pub/Linux/apps/financial/mcalc-1.6.tar.gz  [15k]

echo
echo "Введите сумму займа, процентную ставку и срок займа,"
echo "для расчета суммы ежемесячных выплат."

bottom=1.0

echo
echo -n "Сумма займа (без запятых -- с точностью до доллара) "
read principal
echo -n "Процентная ставка (процент) "  # Если 12%, то нужно вводить "12", а не ".12".
read interest_r
echo -n "Срок займа (месяцев) "
read term


 interest_r=$(echo "scale=9; $interest_r/100.0" | bc) # Здесь "scale" -- точность вычислений.


 interest_rate=$(echo "scale=9; $interest_r/12 + 1.0" | bc)


 top=$(echo "scale=9; $principal*$interest_rate^$term" | bc)

 echo; echo "Прошу подождать. Вычисления потребуют некоторого времени."

 let "months = $term - 1"
# ====================================================================
 for ((x=$months; x > 0; x--))
 do
   bot=$(echo "scale=9; $interest_rate^$x" | bc)
   bottom=$(echo "scale=9; $bottom+$bot" | bc)
#  bottom = $(($bottom + $bot"))
 done
# --------------------------------------------------------------------
#  Rick Boivie предложил более эффективную реализацию
#+ цикла вычислений, который дает выигрыш по времени на 2/3.

# for ((x=1; x <= $months; x++))
# do
#   bottom=$(echo "scale=9; $bottom * $interest_rate + 1" | bc)
# done


#  А затем нашел еще более эффективную альтернативу,
#+ которая выполняется в 20 раз быстрее !!!

# bottom=`{
#     echo "scale=9; bottom=$bottom; interest_rate=$interest_rate"
#     for ((x=1; x <= $months; x++))
#     do
#          echo 'bottom = bottom * interest_rate + 1'
#     done
#     echo 'bottom'
#     } | bc`       # Внедрить цикл 'for' в конструкцию подстановки команд.

# ====================================================================

 # let "payment = $top/$bottom"
 payment=$(echo "scale=2; $top/$bottom" | bc)
 # Два знака после запятой, чтобы показать доллары и центы.

 echo
 echo "ежемесячные выплаты = \$$payment"  # Вывести знак "доллара" перед числом.
 echo


 exit 0

 # Упражнения:
 #   1) Добавьте возможность ввода суммы с точностью до цента.
 #   2) Добавьте возможность ввода процентной ставки как в виде процентов, так и в виде десятичного числа -- доли целого.
 #   3) Если вы действительно честолюбивы,
 #      добавьте в сценарий вывод полной таблицы помесячных выплат.
Пример 12-33. Перевод чисел из одной системы счисления в другую

:
##########################################################################
# Shellscript:  base.sh - вывод чисел в разных системах счисления (Bourne Shell)
# Author     :  Heiner Steven (heiner.steven@odn.de)
# Date       :  07-03-95
# Category   :  Desktop
# $Id: base.sh,v 1.2 2000/02/06 19:55:35 heiner Exp $
##########################################################################
# Description
#
# Changes
# 21-03-95 stv  исправлена ошибка, возникающая при вводе числа 0xb (0.2)
##########################################################################

# ==> Используется в данном документе с разрешения автора.
# ==> Комментарии добавлены автором документа.

NOARGS=65
PN=`basename "$0"`                             # Имя программы
VER=`echo '$Revision: 1.2 $' | cut -d' ' -f2`  # ==> VER=1.2

Usage () {
    echo "$PN - вывод чисел в различных системах счисления, $VER (stv '95)
Порядок использования: $PN [number ...]

Если число не задано, то производится ввод со stdin.
Число может быть:
    двоичное            должно начинаться с комбинации символов 0b (например 0b1100)
    восьмеричное        должно начинаться с 0  (например 014)
    шестнадцатиричное   должно начинаться с комбинации символов 0x (например 0xc)
    десятичное          в любом другом случае (например 12)" >&2
    exit $NOARGS
}   # ==> Функция вывода сообщения о порядке использования.

Msg () {
    for i   # ==> [список] параметров опущен.
    do echo "$PN: $i" >&2
    done
}

Fatal () { Msg "$@"; exit 66; }

PrintBases () {
    # Определение системы счисления
    for i      # ==> [список] параметров опущен...
    do         # ==> поэтому работает с аргументами командной строки.
        case "$i" in
            0b*)                ibase=2;;       # двоичная
            0x*|[a-f]*|[A-F]*)  ibase=16;;      # шестнадцатиричная
            0*)                 ibase=8;;       # восьмеричная
            [1-9]*)             ibase=10;;      # десятичная
            *)
                Msg "Ошибка в числе $i - число проигнорировано"
                continue;;
        esac

        # Удалить префикс и преобразовать шестнадцатиричные цифры в верхний регистр (этого требует bc)
        number=`echo "$i" | sed -e 's:^0[bBxX]::' | tr '[a-f]' '[A-F]'`
        # ==> вместо "/", здесь используется символ ":" как разделитель для sed.

        # Преобразование в десятичную систему счисления
        dec=`echo "ibase=$ibase; $number" | bc`  # ==> 'bc' используется как калькулятор.
        case "$dec" in
            [0-9]*)     ;;       # все в порядке
            *)          continue;; # ошибка: игнорировать
        esac

        # Напечатать все преобразования в одну строку.
        # ==> 'вложенный документ' -- список команд для 'bc'.
        echo `bc <<!
            obase=16; "hex="; $dec
            obase=10; "dec="; $dec
            obase=8;  "oct="; $dec
            obase=2;  "bin="; $dec
!
    ` | sed -e 's: :    :g'

    done
}

while [ $# -gt 0 ]
do
    case "$1" in
        --)     shift; break;;
        -h)     Usage;;          # ==> Вывод справочного сообщения.
        -*)     Usage;;
        *)      break;;          # первое число
    esac   # ==> Хорошо бы расширить анализ вводимых символов.
    shift
done

if [ $# -gt 0 ]
then
    PrintBases "$@"
else                                    # чтение со stdin
    while read line
    do
        PrintBases $line
    done
fi
Один из вариантов вызова bc -- использование вложенного документа, внедряемого в блок с подстановкой команд. Это особенно актуально, когда сценарий должен передать bc значительный по объему список команд и аргументов.

variable=`bc << LIMIT_STRING
options
statements
operations
LIMIT_STRING
`
...или...
variable=$(bc << LIMIT_STRING
options
statements
operations
LIMIT_STRING
)


Пример 12-34. Пример взаимодействия bc со "встроенным документом"

#!/bin/bash
# Комбинирование 'bc' с
# 'вложенным документом'.


var1=`bc << EOF
18.33 * 19.78
EOF
`
echo $var1       # 362.56


#  запись $( ... ) тоже работает.
v1=23.53
v2=17.881
v3=83.501
v4=171.63

var2=$(bc << EOF
scale = 4
a = ( $v1 + $v2 )
b = ( $v3 * $v4 )
a * b + 15.35
EOF
)
echo $var2       # 593487.8452


var3=$(bc -l << EOF
scale = 9
s ( 1.7 )
EOF
)
# Возвращается значение синуса от 1.7 радиана.
# Ключом "-l" вызывается математическая библиотека 'bc'.
echo $var3       # .991664810


# Попробуем функции...
hyp=             # Объявление глобальной переменной.
hypotenuse ()    # Расчет гипотенузы прямоугольного треугольника.
{
hyp=$(bc -l << EOF
scale = 9
sqrt ( $1 * $1 + $2 * $2 )
EOF
)
# К сожалению, функции Bash не могут возвращать числа с плавающей запятой.
}

hypotenuse 3.68 7.31
echo "гипотенуза = $hyp"    # 8.184039344


exit 0
Пример 12-35. Вычисление числа "пи"

#!/bin/bash
# cannon.sh: Аппроксимация числа "пи".

# Это очень простой вариант реализации метода "Monte Carlo",
#+ математическое моделирование событий реальной жизни,
#+ для эмуляции случайного события используются псевдослучайные числа.

#  Допустим, что мы располагаем картой квадратного участка поверхности со стороной квадрата 10000 единиц.
#  На этом участке, в центре, находится совершенно круглое озеро,
#+ с диаметром в 10000 единиц.
#  Т.е. озеро покрывает почти всю карту, кроме ее углов.
#  (Фактически -- это квадрат со вписанным кругом.)
#
#  Пусть по этому участку ведется стрельба железными ядрами из древней пушки
#  Все ядра падают где-то в пределах данного участка,
#+ т.е. либо в озеро, либо на сушу, по углам участка.
#  Поскольку озеро покрывает большую часть участка,
#+ то большинство ядер будет падать в воду.
#  Незначительная часть ядер будет падать на твердую почву.
#
#  Если произвести достаточно большое число неприцельных выстрелов по данному участку,
#+ то отношение попаданий в воду к общему числу выстрелов будет примерно равно
#+ значению PI/4.
#
#  По той простой причине, что стрельба фактически ведется только
#+ по правому верхнему квадранту карты.
#  (Предыдущее описание было несколько упрощено.)
#
#  Теоретически, чем больше будет произведено выстрелов, тем точнее будет результат.
#  Однако, сценарий на языке командной оболочки, в отличие от других языков программирования,
#+ в которых доступны операции с плавающей запятой, имеет некоторые ограничения.
#  К сожалению, это делает вычисления менее точными.


DIMENSION=10000  # Длина стороны квадратного участка поверхности.
                 # Он же -- верхний предел для генератора случайных чисел.

MAXSHOTS=1000    # Количество выстрелов.
                 # 10000 выстрелов (или больше) даст лучший результат,
                                                                 # но потребует значительного количества времени.
PMULTIPLIER=4.0  # Масштабирующий коэффициент.

get_random ()
{
SEED=$(head -1 /dev/urandom | od -N 1 | awk '{ print $2 }')
RANDOM=$SEED                                  #  Из примера "seeding-random.sh"

let "rnum = $RANDOM % $DIMENSION"             #  Число не более чем 10000.
echo $rnum
}

distance=        # Объявление глобальной переменной.
hypotenuse ()    # Расчет гипотенузы прямоугольного треугольника.
{                # Из примера "alt-bc.sh".
distance=$(bc -l << EOF
scale = 0
sqrt ( $1 * $1 + $2 * $2 )
EOF
)
#  Установка "scale" в ноль приводит к округлению результата "вниз",
#+ это и есть то самое ограничение, накладываемое командной оболочкой.
#  Что, к сожалению, снижает точность аппроксимации.
}


# main() {

# Инициализация переменных.
shots=0
splashes=0
thuds=0
Pi=0

while [ "$shots" -lt  "$MAXSHOTS" ]           # Главный цикл.
do

  xCoord=$(get_random)                        # Получить случайные координаты X и Y.
  yCoord=$(get_random)
  hypotenuse $xCoord $yCoord                  #  Гипотенуза = расстоянию.
  ((shots++))

  printf "#%4d   " $shots
  printf "Xc = %4d  " $xCoord
  printf "Yc = %4d  " $yCoord
  printf "Distance = %5d  " $distance         #  Растояние от
                                              #+ центра озера,
                                              #+ с координатами (0,0).

  if [ "$distance" -le "$DIMENSION" ]
  then
    echo -n "ШЛЕП!  "                         # попадание в озеро
    ((splashes++))
  else
    echo -n "БУХ!    "                        # попадание на твердую почву
    ((thuds++))
  fi

  Pi=$(echo "scale=9; $PMULTIPLIER*$splashes/$shots" | bc)
  # Умножение на коэффициент 4.0.
  echo -n "PI ~ $Pi"
  echo

done

echo
echo "После $shots выстрела, примерное значение числа \"пи\" равно $Pi."
# Имеет тенденцию к завышению...
# Вероятно из-за ошибок округления и несовершенства генератора случайных чисел.
echo

# }

exit 0

#  Самое время задуматься над тем, является ли сценарий удобным средством
#+ для выполнения большого количества столь сложных вычислений.
#
#  Тем не менее, этот пример может расцениваться как
#  1) Доказательство возможностей языка командной оболочки.
#  2) Прототип для "обкатки" алгоритма перед тем как перенести
#+    его на высокоуровневые языки программирования компилирующего типа.
dc
Утилита dc (desk calculator) -- это калькулятор, использующий "Обратную Польскую Нотацию", и ориентированный на работу со стеком.

Многие стараются избегать испоьзования dc, из-за непривычной формы записи операндов и операций. Однако, dc имеет и своих сторонников.

Пример 12-36. Преобразование чисел из десятичной в шестнадцатиричную систему счисления

#!/bin/bash
# hexconvert.sh: Преобразование чисел из десятичной в шестнадцатиричную систему счисления.

BASE=16     # Шестнадцатиричная.

if [ -z "$1" ]
then
  echo "Порядок использования: $0 number"
  exit $E_NOARGS
  # Необходим аргумент командной строки.
fi
# Упражнение: добавьте проверку корректности аргумента.


hexcvt ()
{
if [ -z "$1" ]
then
  echo 0
  return    # "Return" 0, если функции не был передан аргумент.
fi

echo ""$1" "$BASE" o p" | dc
#                 "o" устанавливает основание системы счисления для вывода.
#                   "p" выводит число, находящееся на вершине стека.
# См. 'man dc'.
return
}

hexcvt "$1"

exit 0
Изучение страниц info dc позволит детальнее разобраться с утилитой. Однако, отряд "гуру", которые могут похвастать своим знанием этой мощной, но весьма запутанной утилиты, весьма немногочислен.

Пример 12-37. Разложение числа на простые множители

#!/bin/bash
# factr.sh: Разложение числа на простые множители

MIN=2       # Не работает с числами меньше 2.
E_NOARGS=65
E_TOOSMALL=66

if [ -z $1 ]
then
  echo "Порядок использования: $0 number"
  exit $E_NOARGS
fi

if [ "$1" -lt "$MIN" ]
then
  echo "Исходное число должно быть больше или равно $MIN."
  exit $E_TOOSMALL
fi

# Упражнение: Добавьте проверку типа числа (не целые числа должны отвергаться).

echo "Простые множители для числа $1:"
# ---------------------------------------------------------------------------------
echo "$1[p]s2[lip/dli%0=1dvsr]s12sid2%0=13sidvsr[dli%0=1lrli2+dsi!>.]ds.xd1<2" | dc
# ---------------------------------------------------------------------------------
# Автор вышеприведенной строки: Michel Charpentier <charpov@cs.unh.edu>.
# Используется с его разрешения (спасибо).

 exit 0
awk
Еще один способ выполнения математических операций, над числами с плавающей запятой, состоит в создании сценария-обертки, использующего математические функции awk.

Пример 12-38. Расчет гипотенузы прямоугольного треугольника

#!/bin/bash
# hypotenuse.sh: Возвращает "гипотенузу" прямоугольного треугольника.
#               ( корень квадратный от суммы квадратов катетов)

ARGS=2                # В сценарий необходимо передать два катета.
E_BADARGS=65          # Ошибка в аргументах.

if [ $# -ne "$ARGS" ] # Проверка количества аргументов.
then
  echo "Порядок использования: `basename $0` катет_1 катет_2"
  exit $E_BADARGS
fi


AWKSCRIPT=' { printf( "%3.7f\n", sqrt($1*$1 + $2*$2) ) } '
#            команды и параметры, передаваемые в awk


echo -n "Гипотенуза прямоугольного треугольника, с катетами $1 и $2, = "
echo $1 $2 | awk "$AWKSCRIPT"

exit 0

12.9. Прочие команды

Команды, которые нельзя отнести ни к одной из вышеперечисленных категорий

jot, seq
Эти утилиты выводят последовательность целых чисел с шагом, заданным пользователем.

По-умолчанию, выводимые числа отделяются друг от друга символом перевода строки, однако, с помощью ключа -s может быть задан другой разделитель.

bash$ seq 5
1
2
3
4
5



bash$ seq -s : 5
1:2:3:4:5
             


Обе утилиты, и jot, и seq, очень удобно использовать для генерации списка аргументов в цикле for.

Пример 12-39. Использование seq для генерации списка аргументов цикла for

#!/bin/bash
# Утилита "seq"

echo

for a in `seq 80`  # или так:   for a in $( seq 80 )
# То же самое, что и   for a in 1 2 3 4 5 ... 80   (но как экономит время и силы!).
# Можно использовать и 'jot' (если эта утилита имеется в системе).
do
  echo -n "$a "
done      # 1 2 3 4 5 ... 80
# Пример использования вывода команды для генерации
# [списка] аргументов цикла "for".

echo; echo


COUNT=80  # Да, 'seq' допускает указание переменных в качестве параметра.

for a in `seq $COUNT`  # или так:   for a in $( seq $COUNT )
do
  echo -n "$a "
done      # 1 2 3 4 5 ... 80

echo; echo

BEGIN=75
END=80

for a in `seq $BEGIN $END`
#  Если "seq" передаются два аргумента, то первый означает начальное число последовательности,
#+ второй -- последнее,
do
  echo -n "$a "
done      # 75 76 77 78 79 80

echo; echo

BEGIN=45
INTERVAL=5
END=80

for a in `seq $BEGIN $INTERVAL $END`
#  Если "seq" передется три аргумента, то первый аргумент -- начальное число в последовательности,
#+ второй -- шаг последовательности,
#+ и третий -- последнее число в последовательности.
do
  echo -n "$a "
done      # 45 50 55 60 65 70 75 80

echo; echo

exit 0
getopt
Команда getopt служит для разбора командной строки, выделяя из нее ключи -- символы, с предшествующим знаком дефис. Этой утилите имеется, встроенный в Bash, аналог -- getopts, более мощная и универсальная команда.

Пример 12-40. Использование getopt для разбора аргументов командной строки

#!/bin/bash
# ex33a.sh

# Попробуйте следующие варианты вызова этого сценария.
#   sh ex33a -a
#   sh ex33a -abc
#   sh ex33a -a -b -c
#   sh ex33a -d
#   sh ex33a -dXYZ
#   sh ex33a -d XYZ
#   sh ex33a -abcd
#   sh ex33a -abcdZ
#   sh ex33a -z
#   sh ex33a a
# Объясните полученные результаты.

E_OPTERR=65

if [ "$#" -eq 0 ]
then   # Необходим по меньшей мере один аргумент.
  echo "Порядок использования: $0 -[options a,b,c]"
  exit $E_OPTERR
fi

set -- `getopt "abcd:" "$@"`
# Запись аргументов командной строки в позиционные параметры.
# Что произойдет, если вместо "$@" указать "$*"?

while [ ! -z "$1" ]
do
  case "$1" in
    -a) echo "Опция \"a\"";;
    -b) echo "Опция \"b\"";;
    -c) echo "Опция \"c\"";;
    -d) echo "Опция \"d\" $2";;
     *) break;;
  esac

  shift
done

#  Вместо 'getopt' лучше использовать встроенную команду 'getopts',
#  См. "ex33.sh".

exit 0
run-parts
Команда run-parts [1] запускает на исполнение все сценарии, в порядке возрастания имен файлов-сценариев, в заданном каталоге. Естественно, файлы сценариев должны иметь права на исполнение.

Демон crond вызывает run-parts для запуска сценариев из каталогов /etc/cron.*.

yes
По-умолчанию, команда yes выводит на stdout непрерывную последовательность символов y, разделенных символами перевода строки. Исполнение команды можно прервать комбинацией клавиш control-c. Команду yes можно заставить выводить иную последовательность символов. Теперь самое время задаться вопросом о практической пользе этой команды. Основное применение этой команды состоит в том, что вывод от нее может быть передан, через конвейер, другой команде, ожидающей реакции пользователя. В результате получается, своего рода, слабенькая версия команды expect.

yes | fsck /dev/hda1 запускает fsck в неинтерактивном режиме (будьте осторожны!).

yes | rm -r dirname имеет тот же эффект, что и rm -rf dirname (будьте осторожны!).

Warning	
Внимание! Передача вывода команды yes по конвейеру потенциально опасным командам, таким как fsck или fdisk может дать нежелательные побочные эффекты.

banner
Печатает на stdout заданную строку символов (не более 10), рисуя каждый символ строки при помощи символа '#'. Вывод от команды может быть перенаправлен на принтер.

printenv
Выводит все переменные окружения текущего пользователя.

bash$ printenv | grep HOME
HOME=/home/bozo
             


lp
Команды lp и lpr отправляют файлы в очередь печати [2] для вывода на принтер. Названия этих команд произошли от "line printers".

bash$ lp file1.txt или bash lp <file1.txt

Очень часто используются в комбинации с командой форматированного вывода pr.

bash$ pr -options file1.txt | lp

Программы подготовки текста к печати, такие как groff и Ghostscript, так же могут напрямую взаимодействовать с lp.

bash$ groff -Tascii file.tr | lp

bash$ gs -options | lp file.ps

Команда lpq предназначена для просмотра очереди заданий печати, а lprm -- для удаления заданий из очереди.

tee
[UNIX заимствовал эту идею из водопроводного дела.]

Это опрератор перенаправления, но с некоторыми особенностями. Подобно водопроводным трубам, "tee" позволяет "направить поток" данных в несколько файлов и на stdout одновременно, никак не влияя на сами данные. Эта команда может оказаться очень полезной при отладке.

                   tee
                 |------> в файл
                 |
  ===============|===============
  command--->----|-operator-->---> результат работы команд(ы)
  ===============================
             
cat listfile* | sort | tee check.file | uniq > result.file
(Здесь, в файл check.file будут записаны данные из всех "listfile*", в отсортированном виде до того, как повторяющиеся строки будут удалены командой uniq.)

mkfifo
Эта, редко встречающаяся, команда создает именованный канал - очередь, через который производится обмен данными между процессами. [3] Как правило, один процесс записывает данные в очередь (FIFO), а другой читает данные из очереди. См. Пример A-17.

pathchk
Производит проверку полного имени файла -- проверяет, доступны ли на чтение, каталоги в пути к файлу, и не превышает ли длина полного имени файла 255 символов. При несоблюдении одного из условий -- возвращает сообщение об ошибке.

К сожалению, pathchk не возвращает соответствующего кода ошибки, и потому, в общем-то, бесполезна в сценариях. Вместо нее лучше использовать операторы проверки файлов.

dd
Эта немного непонятная и "страшная" команда ("data duplicator") изначально использовалась для переноса данных на магнитной ленте между микрокомпьютерами с ОС UNIX и майнфреймами IBM. Команда dd просто создает копию файла (или stdin/stdout), выполняя по пути некоторые преобразования. Один из вариантов: преобразование из ASCII в EBCDIC, [4] dd --help выведет список возможных вариантов преобразований и опций этой мощной утилиты.

# Изучаем 'dd'.

n=3
p=5
input_file=project.txt
output_file=log.txt

dd if=$input_file of=$output_file bs=1 skip=$((n-1)) count=$((p-n+1)) 2> /dev/null
# Извлечет из $input_file символы с n-го по p-й.




echo -n "hello world" | dd cbs=1 conv=unblock 2> /dev/null
# Выведет "hello world" вертикально.


# Спасибо, S.C.


Для демонстрации возможностей dd, попробуем перехватить нажатия на клавиши.

Пример 12-41. Захват нажатых клавиш

#!/bin/bash
# Захват нажатых клавиш.


keypresses=4                      # Количество фиксируемых нажатий.


old_tty_setting=$(stty -g)        # Сохранить настройки терминала.

echo "Нажмите $keypresses клавиши."
stty -icanon -echo                # Запретить канонический режим.
                                  # Запретить эхо-вывод.
keys=$(dd bs=1 count=$keypresses 2> /dev/null)
# 'dd' использует stdin, если "if" не задан.

stty "$old_tty_setting"           # Восстановить настройки терминала.

echo "Вы нажали клавиши \"$keys\"."

# Спасибо S.C.
exit 0
Команда dd имеет возможность произвольного доступа к данным в потоке.

echo -n . | dd bs=1 seek=4 of=file conv=notrunc
# Здесь, опция "conv=notrunc" означает, что выходной файлне будет усечен.

# Спасибо, S.C.


Команда dd может использоваться для создания образов дисков, считывая данные прямо с устройств, таких как дискеты, компакт диски, магнитные ленты (Пример A-6). Обычно она используется для создания загрузочных дискет.

dd if=kernel-image of=/dev/fd0H1440

Точно так же, dd может скопировать все содержимое дискеты, даже с неизвестной файловой системой, на жесткий диск в виде файла-образа.

dd if=/dev/fd0 of=/home/bozo/projects/floppy.img

Еще одно применение dd -- создание временного swap-файла (Пример 28-2) и ram-дисков (Пример 28-3). Она может создавать даже образы целых разделов жесткого диска, хотя и не рекомендуется делать это без особой на то необходимости.

Многие (которые, вероятно, не знают чем себя занять) постоянно придумывают все новые и новые области применения команды dd.

Пример 12-42. Надежное удаление файла

#!/bin/bash
# blotout.sh: Надежно удаляет файл.

#  Этот суенарий записывает случайные данные в заданный файл,
#+ затем записывает туда нули и наконец удаляет файл.
#  После такого удаления даже анализ дисковых секторов
#+ не даст ровным счетом ничего.

PASSES=7         # Количество проходов по файлу.
BLOCKSIZE=1      #  операции ввода/вывода в/из /dev/urandom требуют указания размера блока,
                 #+ иначе вы не получите желаемого результата.
E_BADARGS=70
E_NOT_FOUND=71
E_CHANGED_MIND=72

if [ -z "$1" ]   # Имя файла не указано.
then
  echo "Порядок использования: `basename $0` filename"
  exit $E_BADARGS
fi

file=$1

if [ ! -e "$file" ]
then
  echo "Файл \"$file\" не найден."
  exit $E_NOT_FOUND
fi

echo; echo -n "Вы совершенно уверены в том, что желаете уничтожить \"$file\" (y/n)? "
read answer
case "$answer" in
[nN]) echo "Передумали? Операция отменена."
      exit $E_CHANGED_MIND
      ;;
*)    echo "Уничтожается файл \"$file\".";;
esac


flength=$(ls -l "$file" | awk '{print $5}')  # Поле с номером 5 -- это длина файла.

pass_count=1

echo

while [ "$pass_count" -le "$PASSES" ]
do
  echo "Проход #$pass_count"
  sync         # Вытолкнуть буферы.
  dd if=/dev/urandom of=$file bs=$BLOCKSIZE count=$flength
               # Заполнить файл случайными данными.
  sync         # Снова вытолкнуть буферы.
  dd if=/dev/zero of=$file bs=$BLOCKSIZE count=$flength
               # Заполнить файл нулями.
  sync         # Снова вытолкнуть буферы.
  let "pass_count += 1"
  echo
done


rm -f $file    # Наконец удалить изрядно "подпорченный" файл.
sync           # Вытолкнуть буферы в последний раз.

echo "Файл \"$file\" уничтожен."; echo


#  Это довольно надежный, хотя и достаточно медленный способ уничтожения файлов.
#+ Более эффективно это делает команда "shred",
#+ входящая в состав пакета GNU "fileutils".

#  Уничтоженный таким образом файл, не сможет быть восстановлен обычными методами.
#  Однако...
#+ эта метода вероятно НЕ сможет противостоять аналитическим службам
#+ из СООТВЕТСТВУЮЩИХ ОРГАНОВ


#  Tom Vier разработал пакет "wipe", который более надежно стирает файлы
#+ чем этот простой сценарий.
#     http://www.ibiblio.org/pub/Linux/utils/file/wipe-2.0.0.tar.bz2

#  Для более глубоко изучения проблемы надежного удаления файлов,
#+ рекомендую обратиться к cnfnmt Peter Gutmann,
#+     "Secure Deletion of Data From Magnetic and Solid-State Memory".
#         http://www.cs.auckland.ac.nz/~pgut001/pubs/secure_del.html


exit 0
od
Команда od (octal dump) производит преобразование ввода (или файла) в один или несколько форматов, в соответствии с указанными опциями. При отсутствии опций используется восьмеричный формат (опция -o). Эта команда полезна при просмотре или обработке файлов с двоичными данными, например /dev/urandom. См. Пример 9-26 и Пример 12-10.

hexdump
Выводит дамп двоичных данных из файла в восьмеричном, шестнадцатиричном, десятичном виде или в виде ASCII. Эту команду, с массой оговорок, можно назвать эквивалентом команды of od.

objdump
Отображает содержимое исполняемого или объектного файла либо в шестнадцатиричной форме, либо в виде дизассемблерного листинга (с ключом -d).

bash$ objdump -d /bin/ls
/bin/ls:     file format elf32-i386

 Disassembly of section .init:

 080490bc <.init>:
  80490bc:       55                      push   %ebp
  80490bd:       89 e5                   mov    %esp,%ebp
  . . .
             


mcookie
Эта команда создает псевдослучайные шестнадцатиричные 128-битные числа, так называемые "magic cookie", обычно используется X-сервером в качестве "сигнатуры" авторизации. В сценариях может использоваться как малоэффективный генератор случайных чисел.

random000=`mcookie | sed -e '2p'`
# 'sed' удаляет посторонние символы.


Конечно, для тех же целей, сценарий может использовать md5.

# Сценарий вычисляет контрольную сумму для самого себя.
random001=`md5sum $0 | awk '{print $1}'`
# 'awk' удаляет имя файла.


С помощью mcookie можно создавать "уникальные" имена файлов.

Пример 12-43. Генератор имен файлов

#!/bin/bash
# tempfile-name.sh:  Генератор имен временных файлов

BASE_STR=`mcookie`   # 32-символьный (128 бит) magic cookie.
POS=11               # Произвольная позиция в строке magic cookie.
LEN=5                # $LEN последовательных символов.

prefix=temp          #  В конце концов это временный ("temp") файл.

suffix=${BASE_STR:POS:LEN}
                     # Извлечь строку, длиной в 5 символов, начиная с позиции 11.

temp_filename=$prefix.$suffix
                     # Сборка имени файла.

echo "Имя временного файла = \"$temp_filename\""

# sh tempfile-name.sh
# Имя временного файла = temp.e19ea

exit 0
units
Эта утилита производит преобразование величин из одних единиц измерения в другие. Как правило вызывается в интерактивном режиме, ниже приводится пример использования units в сценарии.

Пример 12-44. Преобразование метров в мили

#!/bin/bash
# unit-conversion.sh


convert_units ()  # Принимает в качестве входных параметров единицы измерения.
{
  cf=$(units "$1" "$2" | sed --silent -e '1p' | awk '{print $2}')
  # Удаляет все кроме коэффициентов преобразования.
  echo "$cf"
}

Unit1=miles
Unit2=meters
cfactor=`convert_units $Unit1 $Unit2`
quantity=3.73

result=$(echo $quantity*$cfactor | bc)

echo "В $quantity милях $result метров."

#  Что произойдет, если в функцию передать несовместимые единицы измерения,
#+ например "acres" (акры) and "miles" (мили)?

exit 0
m4
Не команда, а клад, m4 -- это мощный фильтр обработки макроопределений, [5] фактически -- целый язык программирования. Изначально создававшаяся как препроцессор для RatFor, m4 оказалась очень полезной и как самостоятельная утилита. Фактически, m4 сочетает в себе функциональные возможности eval, tr, awk, и дополнительно предоставляет обширные возможности по созданию новых макроопределений.

В апрельском выпуске, за 2002 год, журнала Linux Journal вы найдете замечательную статью, описывающую возможности утилиты m4.

Пример 12-45. Пример работы с m4

#!/bin/bash
# m4.sh: Демонстрация некоторых возможносией макропроцессора m4

# Строки
string=abcdA01
echo "len($string)" | m4                           # 7
echo "substr($string,4)" | m4                      # A01
echo "regexp($string,[0-1][0-1],\&Z)" | m4     # 01Z

# Арифметика
echo "incr(22)" | m4                               # 23
echo "eval(99 / 3)" | m4                           # 33

exit 0
doexec
Команда doexec предоставляет возможность передачи произвольного списка аргументов внешней программе. В частности, передавая argv[0] (для сценариев соответствует специальной переменной $0), можно вызвать программу под другим именем, определяя тем самым, ее реакцию.

Например, Пусть в каталоге /usr/local/bin имеется программа с именем "aaa", которая при вызове doexec /usr/local/bin/aaa list выведет список всех файлов в текущем каталоге, имена которых начинаются с символа "a", а при вызове той же самой программы как doexec /usr/local/bin/aaa delete , она удалит эти файлы.

Note	
Естественно, реакция программы на свое собственное имя должна быть реализована в коде программы, для сценария на языке командной оболочки это может выглядеть примерно так:

case `basename $0` in
"name1" ) реакция на вызов под именем name1;;
"name2" ) реакция на вызов под именем name2;;
"name3" ) реакция на вызов под именем name3;;
*       ) действия по-умолчанию;;
esac


Примечания

[1]	
Фактически -- это сценарий, заимствованный из дистрибутива Debian Linux.

[2]	
Очередь печати -- это группа заданий "ожидающих вывода" на принтер.

[3]	
Эта тема прекрасно освещена в статье, которую написал Andy Vaught, Introduction to Named Pipes, в сентябре 1997 для Linux Journal.

[4]	
EBCDIC (произносится как "ebb-sid-ic") -- это аббревиатура от Extended Binary Coded Decimal Interchange Code (Расширенный Двоично-Десятичный Код Обмена Информацией). Это формат представления данных от IBM, не нашедший широкого применения. Не совсем обычное применение опции conv=ebcdic -- это использовать dd для быстрого и легкого, но слабого, шифрования текстовых файлов.

cat $file | dd conv=swab,ebcdic > $file_encrypted
# Зашифрованный файл будет выглядеть как "абракадабра".
# опция swab добавлена для внесения большей неразберихи.

cat $file_encrypted | dd conv=swab,ascii > $file_plaintext
# Декодирование.


[5]	
макроопределение -- это идентификатор, символическая константа, которая представляет некоторую последовательность команд, операций и параметров.


